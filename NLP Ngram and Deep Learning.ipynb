{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13RWPzmNWkh5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random as rand\n",
        "# For regular expressions\n",
        "import re\n",
        "# For handling string\n",
        "import string\n",
        "# For performing mathematical operations\n",
        "import math\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08NBA5prYGCD",
        "outputId": "5c72ae59-a342-4d14-ac81-df4cfee80105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Exploration and Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "1pO2Y4nxdV1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter = pd.read_csv(\"Twitter_Data.csv\",usecols=['clean_text'])\n",
        "print(\"Shape of dataset \",twitter.shape)\n",
        "twitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "W_c7l0Y7Bmv8",
        "outputId": "aeec33a9-cc01-4766-ea3d-fea7c7c3a8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataset  (162980, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               clean_text\n",
              "0       when modi promised “minimum government maximum...\n",
              "1       talk all the nonsense and continue all the dra...\n",
              "2       what did just say vote for modi  welcome bjp t...\n",
              "3       asking his supporters prefix chowkidar their n...\n",
              "4       answer who among these the most powerful world...\n",
              "...                                                   ...\n",
              "162975  why these 456 crores paid neerav modi not reco...\n",
              "162976  dear rss terrorist payal gawar what about modi...\n",
              "162977  did you cover her interaction forum where she ...\n",
              "162978  there big project came into india modi dream p...\n",
              "162979  have you ever listen about like gurukul where ...\n",
              "\n",
              "[162980 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae145e41-df17-4358-a945-a56c812dc70b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer who among these the most powerful world...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162975</th>\n",
              "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162976</th>\n",
              "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162977</th>\n",
              "      <td>did you cover her interaction forum where she ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162978</th>\n",
              "      <td>there big project came into india modi dream p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162979</th>\n",
              "      <td>have you ever listen about like gurukul where ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162980 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae145e41-df17-4358-a945-a56c812dc70b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae145e41-df17-4358-a945-a56c812dc70b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae145e41-df17-4358-a945-a56c812dc70b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data size before preprocessing: \",len(twitter))\n",
        "print(\"Empty Datas :\")\n",
        "twitter.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poQbCOIkXi2M",
        "outputId": "a85c8dc8-075c-46c5-e69a-ac40549541ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data size before preprocessing:  162980\n",
            "Empty Datas :\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clean_text    4\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "IwrL9Q05Xlpo",
        "outputId": "67c8c0df-2f56-4622-f4c9-4ac7bbf84e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               clean_text\n",
              "count                                              162976\n",
              "unique                                             162976\n",
              "top     when modi promised “minimum government maximum...\n",
              "freq                                                    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29a5cfdd-c271-4e92-9d7a-b6ffd57b6468\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>162976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>162976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29a5cfdd-c271-4e92-9d7a-b6ffd57b6468')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29a5cfdd-c271-4e92-9d7a-b6ffd57b6468 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29a5cfdd-c271-4e92-9d7a-b6ffd57b6468');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPF2o6NdXmgy",
        "outputId": "4ee1c330-7a75-4c18-eeaa-ec6eaed1735b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.value_counts()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjwXjde8XsK2",
        "outputId": "2d6e82a0-3398-40a7-8bfc-29e1e8145ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clean_text                                                                                                                                                                                                   \n",
              "\\n\\nasat missile project began two years ago had the concurrence from the says drdo chairman\\n                                                                                                                   1\n",
              "sab gareeb jaise year modi government gaye hain actually pappu having nothing except making some fake promises                                                                                                   1\n",
              "sab chor specially this duo bunty modi and bubbly shah                                                                                                                                                           1\n",
              "sab chowkidar imandar hai mam chodkar dont make chowkidar fool care about chowkidar then fight increase there salary this will not happened last year indian people wiser you bjp guys                           1\n",
              "sab congress supporter modi movie release against haior yaha eros wale modi series release bhi kar                                                                                                               1\n",
              "sab dekho tax payers money modi using                                                                                                                                                                            1\n",
              "sab dhikhawa hai has created committee but need committee simply decide that when moral code conduct place then modi still doing the same thing which used before they also not taking action namo namo movie    1\n",
              "sab election time riha smart modi waise                                                                                                                                                                          1\n",
              "sab election time yaad aatamodi already doingdont need your ideas                                                                                                                                                1\n",
              "sab hoga dont worry just wait till 23rd may modi will back kick all courpt people                                                                                                                                1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Db4PmF1YFKc",
        "outputId": "38a194f4-9114-4236-911a-c0d573a4408d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 162980 entries, 0 to 162979\n",
            "Data columns (total 1 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   clean_text  162976 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8aIStlLps-vO",
        "outputId": "bd1b4cf3-94e1-449a-ec53-a25e6184204c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.dropna(inplace=True)\n",
        "twitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7r40s4jpW2e4",
        "outputId": "eace2f06-bdfb-4e59-eefc-fd5c5a59bd14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               clean_text\n",
              "0       when modi promised “minimum government maximum...\n",
              "1       talk all the nonsense and continue all the dra...\n",
              "2       what did just say vote for modi  welcome bjp t...\n",
              "3       asking his supporters prefix chowkidar their n...\n",
              "4       answer who among these the most powerful world...\n",
              "...                                                   ...\n",
              "162975  why these 456 crores paid neerav modi not reco...\n",
              "162976  dear rss terrorist payal gawar what about modi...\n",
              "162977  did you cover her interaction forum where she ...\n",
              "162978  there big project came into india modi dream p...\n",
              "162979  have you ever listen about like gurukul where ...\n",
              "\n",
              "[162976 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0265919-5adf-4f06-b47d-b7aba0309908\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer who among these the most powerful world...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162975</th>\n",
              "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162976</th>\n",
              "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162977</th>\n",
              "      <td>did you cover her interaction forum where she ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162978</th>\n",
              "      <td>there big project came into india modi dream p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162979</th>\n",
              "      <td>have you ever listen about like gurukul where ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162976 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0265919-5adf-4f06-b47d-b7aba0309908')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0265919-5adf-4f06-b47d-b7aba0309908 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0265919-5adf-4f06-b47d-b7aba0309908');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBmL1dUeuBCl",
        "outputId": "286271bd-4b5f-4596-9b9b-27c7fa1dc727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clean_text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DatasetTargetToArray(dataset,label_target=None):\n",
        "  if label_target != None:\n",
        "    arr = dataset[[label_target]].to_numpy()\n",
        "    label = []\n",
        "    for i in arr:\n",
        "      label.append(i[0])\n",
        "    return dataset.drop(columns=[label_target]).to_numpy(),np.array(label)\n",
        "  else: return dataset.to_numpy()\n",
        "\n",
        "arr = DatasetTargetToArray(twitter)\n",
        "arr[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZt_4uQpaD4g",
        "outputId": "eb844d4e-6bd3-4d21-a79e-00c575f33f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples'],\n",
              "       ['talk all the nonsense and continue all the drama will vote for modi '],\n",
              "       ['what did just say vote for modi  welcome bjp told you rahul the main campaigner for modi think modi should just relax'],\n",
              "       ['asking his supporters prefix chowkidar their names modi did great service now there confusion what read what not now crustal clear what will crass filthy nonsensical see how most abuses are coming from chowkidars'],\n",
              "       ['answer who among these the most powerful world leader today trump putin modi may '],\n",
              "       ['kiya tho refresh maarkefir comment karo '],\n",
              "       ['surat women perform yagna seeks divine grace for narendra modi become again\\n'],\n",
              "       ['this comes from cabinet which has scholars like modi smriti and hema time introspect'],\n",
              "       ['with upcoming election india saga going important pair look current modi leads govt elected with deal brexit combination this weekly looks juicy bears imho '],\n",
              "       ['gandhi was gay does modi  ']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NGRAM LANGUAGE MODEL"
      ],
      "metadata": {
        "id": "IR1sNQBRRzBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaningTweet(text):\n",
        "  ans = text.replace(\"RT \", \"\")\n",
        "  ans = ans.replace(\"RT\", \"\")\n",
        "  ans = re.sub(r'[^\\w\\s]','',ans)\n",
        "  ans = ans + \" <eos>\"\n",
        "  ans = re.sub('\\\\s+', ' ', ans).lower()\n",
        "  return ans\n",
        "\n",
        "cleaningTweet(\"surat women perform yagna seeks divine grace for narendra modi become again\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gjGC_uBYWy5y",
        "outputId": "ecffb23a-dbe5-48da-f803-fa878508895c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'surat women perform yagna seeks divine grace for narendra modi become again <eos>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_N_grams(text,ngram=1):\n",
        "  #separete split by white space and then remove the stopwords\n",
        "  text = cleaningTweet(text)\n",
        "  words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]\n",
        "  #print(text,words)\n",
        "  ans = []\n",
        "  i=0\n",
        "  while 1:\n",
        "    wgram=[]\n",
        "    for w in words[i:ngram+i] :\n",
        "      wgram.append(w)\n",
        "\n",
        "    ans.append(tuple(wgram))\n",
        "    if wgram[len(wgram)-1]==words[len(words)-1]:\n",
        "      break\n",
        "    i+=1\n",
        "  #temp=zip(*[words[i:] for i in range(0,ngram)])\n",
        "  #ans=[' '.join(ngram) for ngram in temp]\n",
        "  return ans\n",
        "\n",
        "generate_N_grams(\"surat women perform yagna seeks divine grace for narendra modi become again\\n\",3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfBwYdyMaaXo",
        "outputId": "f9781067-d264-4041-93fd-a1b247360e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('surat', 'women', 'perform'),\n",
              " ('women', 'perform', 'yagna'),\n",
              " ('perform', 'yagna', 'seeks'),\n",
              " ('yagna', 'seeks', 'divine'),\n",
              " ('seeks', 'divine', 'grace'),\n",
              " ('divine', 'grace', 'narendra'),\n",
              " ('grace', 'narendra', 'modi'),\n",
              " ('narendra', 'modi', 'become'),\n",
              " ('modi', 'become', '<eos>')]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def N_Grams(arr,ngram=1,dataframe=True):\n",
        "\n",
        "  values = {}\n",
        "  for i in range(len(arr)):\n",
        "    text = arr[i][0]\n",
        "    #print(text)\n",
        "    for word in generate_N_grams(text,ngram):\n",
        "      try:\n",
        "        values[word]+=1\n",
        "      except :\n",
        "        values[word]=1\n",
        "  if not dataframe :\n",
        "    return sorted(values.items(),key=lambda x:x[1],reverse=True)\n",
        "  return pd.DataFrame(sorted(values.items(),key=lambda x:x[1],reverse=True))\n",
        "\n",
        "dfgram = N_Grams(arr[:100],3)\n",
        "dfgram.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "wZbqPCaPad4W",
        "outputId": "69423ca7-5a61-45af-b34b-0fa8420b9501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            0  1\n",
              "0            (via, namo, app)  3\n",
              "1          (namo, app, <eos>)  3\n",
              "2           (one, vote, make)  2\n",
              "3    (vote, make, difference)  2\n",
              "4    (make, difference, anil)  2\n",
              "5  (difference, anil, kapoor)  2\n",
              "6     (anil, kapoor, answers)  2\n",
              "7    (kapoor, answers, modis)  2\n",
              "8  (answers, modis, election)  2\n",
              "9     (modis, election, 2019)  2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5e6ace0-6dbb-4cfd-9aba-55ed99b3314a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(via, namo, app)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(namo, app, &lt;eos&gt;)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(one, vote, make)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(vote, make, difference)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(make, difference, anil)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(difference, anil, kapoor)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(anil, kapoor, answers)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(kapoor, answers, modis)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(answers, modis, election)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(modis, election, 2019)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5e6ace0-6dbb-4cfd-9aba-55ed99b3314a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5e6ace0-6dbb-4cfd-9aba-55ed99b3314a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5e6ace0-6dbb-4cfd-9aba-55ed99b3314a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_Grams(arr[:100],3,dataframe=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3NauYm8a7ei",
        "outputId": "b994f9bf-b5c5-4eac-b92c-879042bcb42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('vote', 'modi'), 8),\n",
              " (('narendra', 'modi'), 8),\n",
              " (('modi', '<eos>'), 5),\n",
              " (('modi', 'govt'), 5),\n",
              " (('new', 'india'), 5),\n",
              " (('modi', 'govts'), 4),\n",
              " (('modi', 'government'), 4),\n",
              " (('modi', 'great'), 3),\n",
              " (('vote', 'kar'), 3),\n",
              " (('campaign', '<eos>'), 3),\n",
              " (('modi', 'bjp'), 3),\n",
              " (('via', '<eos>'), 3),\n",
              " (('corruption', 'free'), 3),\n",
              " (('via', 'namo'), 3),\n",
              " (('namo', 'app'), 3),\n",
              " (('app', '<eos>'), 3),\n",
              " (('prime', 'minister'), 3),\n",
              " (('exit', 'psus'), 2),\n",
              " (('like', 'modi'), 2),\n",
              " (('minister', 'modi'), 2),\n",
              " (('modi', 'cabinet'), 2),\n",
              " (('one', 'vote'), 2),\n",
              " (('vote', 'make'), 2),\n",
              " (('make', 'difference'), 2),\n",
              " (('difference', 'anil'), 2),\n",
              " (('anil', 'kapoor'), 2),\n",
              " (('kapoor', 'answers'), 2),\n",
              " (('answers', 'modis'), 2),\n",
              " (('modis', 'election'), 2),\n",
              " (('election', '2019'), 2),\n",
              " (('2019', 'clarion'), 2),\n",
              " (('clarion', 'call'), 2),\n",
              " (('call', 'extends'), 2),\n",
              " (('extends', 'support'), 2),\n",
              " (('bjp', 'party'), 2),\n",
              " (('vote', 'ensure'), 2),\n",
              " (('ensure', 'govt'), 2),\n",
              " (('govt', 'need'), 2),\n",
              " (('need', 'deserve'), 2),\n",
              " (('deserve', 'anupam'), 2),\n",
              " (('anupam', 'kher'), 2),\n",
              " (('kher', 'responds'), 2),\n",
              " (('responds', 'modis'), 2),\n",
              " (('appeal', '2019'), 2),\n",
              " (('2019', 'elections'), 2),\n",
              " (('elections', '<eos>'), 2),\n",
              " (('modi', 'anti'), 2),\n",
              " (('anti', 'national'), 2),\n",
              " (('shri', 'narendra'), 2),\n",
              " (('india', '<eos>'), 2),\n",
              " (('modi', 'also'), 2),\n",
              " (('nirav', 'modi'), 2),\n",
              " (('free', 'india'), 2),\n",
              " (('india', 'modi'), 2),\n",
              " (('modi', 'rss'), 2),\n",
              " (('years', 'governance'), 2),\n",
              " (('policies', 'question'), 2),\n",
              " (('last', 'time'), 2),\n",
              " (('yogi', 'adityanath'), 2),\n",
              " (('modi', 'promised'), 1),\n",
              " (('promised', 'minimum'), 1),\n",
              " (('minimum', 'government'), 1),\n",
              " (('government', 'maximum'), 1),\n",
              " (('maximum', 'governance'), 1),\n",
              " (('governance', 'expected'), 1),\n",
              " (('expected', 'begin'), 1),\n",
              " (('begin', 'difficult'), 1),\n",
              " (('difficult', 'job'), 1),\n",
              " (('job', 'reforming'), 1),\n",
              " (('reforming', 'state'), 1),\n",
              " (('state', 'take'), 1),\n",
              " (('take', 'years'), 1),\n",
              " (('years', 'get'), 1),\n",
              " (('get', 'justice'), 1),\n",
              " (('justice', 'state'), 1),\n",
              " (('state', 'business'), 1),\n",
              " (('business', 'exit'), 1),\n",
              " (('psus', 'temples'), 1),\n",
              " (('temples', '<eos>'), 1),\n",
              " (('talk', 'nonsense'), 1),\n",
              " (('nonsense', 'continue'), 1),\n",
              " (('continue', 'drama'), 1),\n",
              " (('drama', 'vote'), 1),\n",
              " (('say', 'vote'), 1),\n",
              " (('modi', 'welcome'), 1),\n",
              " (('welcome', 'bjp'), 1),\n",
              " (('bjp', 'told'), 1),\n",
              " (('told', 'rahul'), 1),\n",
              " (('rahul', 'main'), 1),\n",
              " (('main', 'campaigner'), 1),\n",
              " (('campaigner', 'modi'), 1),\n",
              " (('modi', 'think'), 1),\n",
              " (('think', 'modi'), 1),\n",
              " (('modi', 'relax'), 1),\n",
              " (('relax', '<eos>'), 1),\n",
              " (('asking', 'supporters'), 1),\n",
              " (('supporters', 'prefix'), 1),\n",
              " (('prefix', 'chowkidar'), 1),\n",
              " (('chowkidar', 'names'), 1),\n",
              " (('names', 'modi'), 1),\n",
              " (('great', 'service'), 1),\n",
              " (('service', 'confusion'), 1),\n",
              " (('confusion', 'read'), 1),\n",
              " (('read', 'crustal'), 1),\n",
              " (('crustal', 'clear'), 1),\n",
              " (('clear', 'crass'), 1),\n",
              " (('crass', 'filthy'), 1),\n",
              " (('filthy', 'nonsensical'), 1),\n",
              " (('nonsensical', 'see'), 1),\n",
              " (('see', 'abuses'), 1),\n",
              " (('abuses', 'coming'), 1),\n",
              " (('coming', 'chowkidars'), 1),\n",
              " (('chowkidars', '<eos>'), 1),\n",
              " (('answer', 'among'), 1),\n",
              " (('among', 'powerful'), 1),\n",
              " (('powerful', 'world'), 1),\n",
              " (('world', 'leader'), 1),\n",
              " (('leader', 'today'), 1),\n",
              " (('today', 'trump'), 1),\n",
              " (('trump', 'putin'), 1),\n",
              " (('putin', 'modi'), 1),\n",
              " (('modi', 'may'), 1),\n",
              " (('may', '<eos>'), 1),\n",
              " (('kiya', 'tho'), 1),\n",
              " (('tho', 'refresh'), 1),\n",
              " (('refresh', 'maarkefir'), 1),\n",
              " (('maarkefir', 'comment'), 1),\n",
              " (('comment', 'karo'), 1),\n",
              " (('karo', '<eos>'), 1),\n",
              " (('surat', 'women'), 1),\n",
              " (('women', 'perform'), 1),\n",
              " (('perform', 'yagna'), 1),\n",
              " (('yagna', 'seeks'), 1),\n",
              " (('seeks', 'divine'), 1),\n",
              " (('divine', 'grace'), 1),\n",
              " (('grace', 'narendra'), 1),\n",
              " (('modi', 'become'), 1),\n",
              " (('become', '<eos>'), 1),\n",
              " (('comes', 'cabinet'), 1),\n",
              " (('cabinet', 'scholars'), 1),\n",
              " (('scholars', 'like'), 1),\n",
              " (('modi', 'smriti'), 1),\n",
              " (('smriti', 'hema'), 1),\n",
              " (('hema', 'time'), 1),\n",
              " (('time', 'introspect'), 1),\n",
              " (('introspect', '<eos>'), 1),\n",
              " (('upcoming', 'election'), 1),\n",
              " (('election', 'india'), 1),\n",
              " (('india', 'saga'), 1),\n",
              " (('saga', 'going'), 1),\n",
              " (('going', 'important'), 1),\n",
              " (('important', 'pair'), 1),\n",
              " (('pair', 'look'), 1),\n",
              " (('look', 'current'), 1),\n",
              " (('current', 'modi'), 1),\n",
              " (('modi', 'leads'), 1),\n",
              " (('leads', 'govt'), 1),\n",
              " (('govt', 'elected'), 1),\n",
              " (('elected', 'deal'), 1),\n",
              " (('deal', 'brexit'), 1),\n",
              " (('brexit', 'combination'), 1),\n",
              " (('combination', 'weekly'), 1),\n",
              " (('weekly', 'looks'), 1),\n",
              " (('looks', 'juicy'), 1),\n",
              " (('juicy', 'bears'), 1),\n",
              " (('bears', 'imho'), 1),\n",
              " (('imho', '<eos>'), 1),\n",
              " (('gandhi', 'gay'), 1),\n",
              " (('gay', 'modi'), 1),\n",
              " (('things', 'like'), 1),\n",
              " (('like', 'demonetisation'), 1),\n",
              " (('demonetisation', 'gst'), 1),\n",
              " (('gst', 'goods'), 1),\n",
              " (('goods', 'services'), 1),\n",
              " (('services', 'taxthe'), 1),\n",
              " (('taxthe', 'upper'), 1),\n",
              " (('upper', 'castes'), 1),\n",
              " (('castes', 'would'), 1),\n",
              " (('would', 'sort'), 1),\n",
              " (('sort', 'either'), 1),\n",
              " (('either', 'view'), 1),\n",
              " (('view', 'favourably'), 1),\n",
              " (('favourably', 'say'), 1),\n",
              " (('say', 'need'), 1),\n",
              " (('need', 'give'), 1),\n",
              " (('give', 'time'), 1),\n",
              " (('time', 'castes'), 1),\n",
              " (('castes', 'like'), 1),\n",
              " (('like', 'dalits'), 1),\n",
              " (('dalits', 'muslims'), 1),\n",
              " (('muslims', 'modi'), 1),\n",
              " (('modi', 'constituency2'), 1),\n",
              " (('constituency2', '<eos>'), 1),\n",
              " (('hope', 'tuthukudi'), 1),\n",
              " (('tuthukudi', 'people'), 1),\n",
              " (('people', 'would'), 1),\n",
              " (('would', 'prefer'), 1),\n",
              " (('prefer', 'honest'), 1),\n",
              " (('honest', 'well'), 1),\n",
              " (('well', 'behaved'), 1),\n",
              " (('behaved', 'nationalist'), 1),\n",
              " (('nationalist', 'courageous'), 1),\n",
              " (('courageous', 'likly'), 1),\n",
              " (('likly', 'minister'), 1),\n",
              " (('cabinet', 'vote'), 1),\n",
              " (('vote', 'benifit'), 1),\n",
              " (('benifit', 'thuthukudi'), 1),\n",
              " (('thuthukudi', '<eos>'), 1),\n",
              " (('calm', 'waters'), 1),\n",
              " (('waters', 'wheres'), 1),\n",
              " (('wheres', 'modi'), 1),\n",
              " (('modi', 'wave'), 1),\n",
              " (('wave', '<eos>'), 1),\n",
              " (('support', 'vote'), 1),\n",
              " (('kar', 'campaign'), 1),\n",
              " (('support', 'campaign'), 1),\n",
              " (('vote', 'party'), 1),\n",
              " (('party', 'leadershipwho'), 1),\n",
              " (('leadershipwho', 'take'), 1),\n",
              " (('take', 'fast'), 1),\n",
              " (('fast', 'firm'), 1),\n",
              " (('firm', 'action'), 1),\n",
              " (('action', 'none'), 1),\n",
              " (('none', 'narendra'), 1),\n",
              " (('narendra', 'damodardas'), 1),\n",
              " (('damodardas', 'modi'), 1),\n",
              " (('party', '<eos>'), 1),\n",
              " (('modi', 'created'), 1),\n",
              " (('created', 'jobs'), 1),\n",
              " (('jobs', '<eos>'), 1),\n",
              " (('modis', 'appeal'), 1),\n",
              " (('dont', 'play'), 1),\n",
              " (('play', 'words'), 1),\n",
              " (('words', 'talking'), 1),\n",
              " (('talking', 'modi'), 1),\n",
              " (('modi', 'swamy'), 1),\n",
              " (('swamy', 'relation'), 1),\n",
              " (('relation', 'guru'), 1),\n",
              " (('guru', 'saying'), 1),\n",
              " (('saying', 'good'), 1),\n",
              " (('good', 'chowkidar'), 1),\n",
              " (('chowkidar', 'protecting'), 1),\n",
              " (('protecting', 'good'), 1),\n",
              " (('good', 'mind'), 1),\n",
              " (('mind', 'tweeted'), 1),\n",
              " (('tweeted', 'dark'), 1),\n",
              " (('dark', 'side'), 1),\n",
              " (('side', 'terrorism'), 1),\n",
              " (('terrorism', 'brighter'), 1),\n",
              " (('brighter', 'side'), 1),\n",
              " (('side', 'better'), 1),\n",
              " (('better', 'know'), 1),\n",
              " (('know', '<eos>'), 1),\n",
              " (('write', 'chowkidar'), 1),\n",
              " (('chowkidar', 'mean'), 1),\n",
              " (('mean', 'anti'), 1),\n",
              " (('anti', 'modi'), 1),\n",
              " (('modi', 'try'), 1),\n",
              " (('try', 'visit'), 1),\n",
              " (('visit', 'plz'), 1),\n",
              " (('plz', 'used'), 1),\n",
              " (('used', 'anti'), 1),\n",
              " (('anti', '<eos>'), 1),\n",
              " (('one', 'recently'), 1),\n",
              " (('recently', 'said'), 1),\n",
              " (('said', 'people'), 1),\n",
              " (('people', 'vote'), 1),\n",
              " (('national', 'put'), 1),\n",
              " (('put', 'gen'), 1),\n",
              " (('gen', 'hooda'), 1),\n",
              " (('hooda', 'congress'), 1),\n",
              " (('congress', 'supporters'), 1),\n",
              " (('supporters', 'jawans'), 1),\n",
              " (('jawans', 'support'), 1),\n",
              " (('support', 'modi'), 1),\n",
              " (('national', 'great'), 1),\n",
              " (('great', 'things'), 1),\n",
              " (('things', 'hear'), 1),\n",
              " (('hear', '<eos>'), 1),\n",
              " (('firm', 'belief'), 1),\n",
              " (('belief', 'leadership'), 1),\n",
              " (('leadership', 'shri'), 1),\n",
              " (('bjp', 'entering'), 1),\n",
              " (('entering', 'politics'), 1),\n",
              " (('politics', 'given'), 1),\n",
              " (('given', 'form'), 1),\n",
              " (('form', 'file'), 1),\n",
              " (('file', 'nomination'), 1),\n",
              " (('nomination', 'khammam'), 1),\n",
              " (('khammam', 'parliamentary'), 1),\n",
              " (('parliamentary', 'seat'), 1),\n",
              " (('seat', 'proceeding'), 1),\n",
              " (('proceeding', 'khammam'), 1),\n",
              " (('khammam', 'today'), 1),\n",
              " (('today', '<eos>'), 1),\n",
              " (('crush', 'jaws'), 1),\n",
              " (('jaws', 'shoutmodimodi'), 1),\n",
              " (('shoutmodimodi', 'says'), 1),\n",
              " (('says', 'jds'), 1),\n",
              " (('jds', 'mla'), 1),\n",
              " (('mla', 'inciting'), 1),\n",
              " (('inciting', 'murder'), 1),\n",
              " (('murder', '<eos>'), 1),\n",
              " (('sultanpur', 'uttar'), 1),\n",
              " (('uttar', 'pradesh'), 1),\n",
              " (('pradesh', 'loksabha'), 1),\n",
              " (('loksabha', 'candidate'), 1),\n",
              " (('candidate', 'select'), 1),\n",
              " (('select', 'pawan'), 1),\n",
              " (('pawan', 'kumar'), 1),\n",
              " (('kumar', 'pandey'), 1),\n",
              " (('pandey', 'actually'), 1),\n",
              " (('actually', 'public'), 1),\n",
              " (('public', 'want'), 1),\n",
              " (('want', 'given'), 1),\n",
              " (('given', 'vote'), 1),\n",
              " (('modi', 'current'), 1),\n",
              " (('current', 'condidate'), 1),\n",
              " (('condidate', 'popular'), 1),\n",
              " (('popular', 'district'), 1),\n",
              " (('district', 'candidate'), 1),\n",
              " (('candidate', 'bsp'), 1),\n",
              " (('bsp', 'candidate'), 1),\n",
              " (('candidate', 'sonbhadra'), 1),\n",
              " (('sonbhadra', 'singh'), 1),\n",
              " (('singh', '<eos>'), 1),\n",
              " (('thiugh', 'nehru'), 1),\n",
              " (('nehru', 'alive'), 1),\n",
              " (('alive', 'still'), 1),\n",
              " (('still', 'alive'), 1),\n",
              " (('alive', 'heart'), 1),\n",
              " (('heart', 'modi'), 1),\n",
              " (('modi', 'every'), 1),\n",
              " (('every', 'failure'), 1),\n",
              " (('failure', 'nehru'), 1),\n",
              " (('nehru', 'responsible'), 1),\n",
              " (('responsible', '<eos>'), 1),\n",
              " (('', 'development'), 1),\n",
              " (('development', 'become'), 1),\n",
              " (('become', 'mass'), 1),\n",
              " (('mass', 'movement'), 1),\n",
              " (('movement', 'modi'), 1),\n",
              " (('govt', 'economic'), 1),\n",
              " (('economic', 'social'), 1),\n",
              " (('social', 'political'), 1),\n",
              " (('political', 'empowerment'), 1),\n",
              " (('empowerment', 'life'), 1),\n",
              " (('life', 'one'), 1),\n",
              " (('one', 'witnessed'), 1),\n",
              " (('witnessed', 'positive'), 1),\n",
              " (('positive', 'paradigm'), 1),\n",
              " (('paradigm', 'shift'), 1),\n",
              " (('shift', 'new'), 1),\n",
              " (('already', 'taken'), 1),\n",
              " (('taken', 'notice'), 1),\n",
              " (('notice', 'ordered'), 1),\n",
              " (('ordered', 'probe'), 1),\n",
              " (('probe', 'time'), 1),\n",
              " (('time', 'modi'), 1),\n",
              " (('modi', 'take'), 1),\n",
              " (('take', 'notice'), 1),\n",
              " (('notice', 'muslim'), 1),\n",
              " (('muslim', 'family'), 1),\n",
              " (('family', 'harassed'), 1),\n",
              " (('harassed', 'beaten'), 1),\n",
              " (('beaten', 'recently'), 1),\n",
              " (('recently', 'extremist'), 1),\n",
              " (('extremist', 'hindus'), 1),\n",
              " (('hindus', 'suggested'), 1),\n",
              " (('suggested', 'leave'), 1),\n",
              " (('leave', 'india'), 1),\n",
              " (('india', 'move'), 1),\n",
              " (('move', 'pakistan'), 1),\n",
              " (('pakistan', '<eos>'), 1),\n",
              " (('waiting', 'modi'), 1),\n",
              " (('also', 'talk'), 1),\n",
              " (('talk', 'varanasi'), 1),\n",
              " (('varanasi', '<eos>'), 1),\n",
              " (('according', 'yogi'), 1),\n",
              " (('yogi', 'imran'), 1),\n",
              " (('imran', 'masood'), 1),\n",
              " (('masood', 'kin'), 1),\n",
              " (('kin', 'azhar'), 1),\n",
              " (('azhar', 'masood'), 1),\n",
              " (('masood', 'according'), 1),\n",
              " (('according', 'logic'), 1),\n",
              " (('logic', 'nirav'), 1),\n",
              " (('modi', 'lalit'), 1),\n",
              " (('lalit', 'modi'), 1),\n",
              " (('modi', 'narendra'), 1),\n",
              " (('modi', 'brothers'), 1),\n",
              " (('brothers', 'mother'), 1),\n",
              " (('mother', '<eos>'), 1),\n",
              " (('agree', 'tenure'), 1),\n",
              " (('tenure', 'modiganga'), 1),\n",
              " (('modiganga', 'rejuvenation'), 1),\n",
              " (('rejuvenation', 'works'), 1),\n",
              " (('works', 'started'), 1),\n",
              " (('started', 'working'), 1),\n",
              " (('working', '<eos>'), 1),\n",
              " (('three', 'codes'), 1),\n",
              " (('codes', 'modi'), 1),\n",
              " (('modi', 'cracked'), 1),\n",
              " (('cracked', 'give'), 1),\n",
              " (('give', 'india'), 1),\n",
              " (('india', 'huge'), 1),\n",
              " (('huge', 'foreign'), 1),\n",
              " (('foreign', 'policy'), 1),\n",
              " (('policy', 'jumpstart'), 1),\n",
              " (('jumpstart', 'via'), 1),\n",
              " (('modis', 'vote'), 1),\n",
              " (('kar', 'appeal'), 1),\n",
              " (('govts', 'slashing'), 1),\n",
              " (('slashing', 'indias'), 1),\n",
              " (('indias', 'education'), 1),\n",
              " (('education', 'budget'), 1),\n",
              " (('budget', 'clear'), 1),\n",
              " (('clear', 'indicator'), 1),\n",
              " (('indicator', 'dont'), 1),\n",
              " (('dont', 'care'), 1),\n",
              " (('care', 'indias'), 1),\n",
              " (('indias', 'future'), 1),\n",
              " (('future', 'congress'), 1),\n",
              " (('congress', 'president'), 1),\n",
              " (('president', 'shri'), 1),\n",
              " (('shri', 'hand'), 1),\n",
              " (('hand', 'ensured'), 1),\n",
              " (('ensured', 'increase'), 1),\n",
              " (('increase', 'budget'), 1),\n",
              " (('budget', 'gdp'), 1),\n",
              " (('gdp', 'future'), 1),\n",
              " (('future', 'india'), 1),\n",
              " (('india', 'deserves'), 1),\n",
              " (('deserves', '<eos>'), 1),\n",
              " (('born', 'religion'), 1),\n",
              " (('religion', 'female'), 1),\n",
              " (('female', 'deities'), 1),\n",
              " (('deities', 'worshipped'), 1),\n",
              " (('worshipped', 'misogynistic'), 1),\n",
              " (('misogynistic', 'sadistic'), 1),\n",
              " (('sadistic', 'tradition'), 1),\n",
              " (('tradition', 'totally'), 1),\n",
              " (('totally', 'point'), 1),\n",
              " (('point', 'isits'), 1),\n",
              " (('isits', 'man'), 1),\n",
              " (('man', 'made'), 1),\n",
              " (('made', 'tradition'), 1),\n",
              " (('tradition', 'written'), 1),\n",
              " (('written', 'one'), 1),\n",
              " (('one', 'religious'), 1),\n",
              " (('religious', 'lunatic'), 1),\n",
              " (('lunatic', 'support'), 1),\n",
              " (('support', 'religion'), 1),\n",
              " (('religion', 'repressive'), 1),\n",
              " (('repressive', '<eos>'), 1),\n",
              " (('people', 'made'), 1),\n",
              " (('made', 'amazedn'), 1),\n",
              " (('amazedn', 'fear'), 1),\n",
              " (('fear', 'frustation'), 1),\n",
              " (('frustation', 'may'), 1),\n",
              " (('may', 'result'), 1),\n",
              " (('result', 'vote'), 1),\n",
              " (('vote', 'sir'), 1),\n",
              " (('sir', 'waste'), 1),\n",
              " (('waste', 'ministerdisgrace'), 1),\n",
              " (('ministerdisgrace', 'entire'), 1),\n",
              " (('entire', 'modi'), 1),\n",
              " (('cabinet', '<eos>'), 1),\n",
              " (('check', 'latest'), 1),\n",
              " (('latest', 'article'), 1),\n",
              " (('article', 'premier'), 1),\n",
              " (('premier', 'archery'), 1),\n",
              " (('archery', 'league'), 1),\n",
              " (('league', 'via'), 1),\n",
              " (('india', 'second'), 1),\n",
              " (('second', 'optimistic'), 1),\n",
              " (('optimistic', 'globally'), 1),\n",
              " (('globally', 'executive'), 1),\n",
              " (('executive', 'job'), 1),\n",
              " (('job', 'growth'), 1),\n",
              " (('growth', 'shows'), 1),\n",
              " (('shows', 'survey'), 1),\n",
              " (('survey', 'indias'), 1),\n",
              " (('indias', 'senior'), 1),\n",
              " (('senior', 'executives'), 1),\n",
              " (('executives', 'said'), 1),\n",
              " (('said', 'optimistic'), 1),\n",
              " (('optimistic', 'growth'), 1),\n",
              " (('growth', 'number'), 1),\n",
              " (('number', 'job'), 1),\n",
              " (('job', 'roles'), 1),\n",
              " (('roles', 'year'), 1),\n",
              " (('year', '<eos>'), 1),\n",
              " (('people', 'wish'), 1),\n",
              " (('wish', 'vision'), 1),\n",
              " (('vision', 'india'), 1),\n",
              " (('india', 'least'), 1),\n",
              " (('least', 'interested'), 1),\n",
              " (('interested', 'personal'), 1),\n",
              " (('personal', 'enmity'), 1),\n",
              " (('enmity', 'modi'), 1),\n",
              " (('modi', 'others'), 1),\n",
              " (('others', 'personal'), 1),\n",
              " (('personal', 'problem'), 1),\n",
              " (('problem', 'handle'), 1),\n",
              " (('handle', 'personally'), 1),\n",
              " (('personally', 'dont'), 1),\n",
              " (('dont', 'expect'), 1),\n",
              " (('expect', 'nation'), 1),\n",
              " (('nation', 'join'), 1),\n",
              " (('join', 'dirty'), 1),\n",
              " (('dirty', 'fight'), 1),\n",
              " (('fight', 'others'), 1),\n",
              " (('others', 'tell'), 1),\n",
              " (('tell', 'vote'), 1),\n",
              " (('vote', '<eos>'), 1),\n",
              " (('modi', 'eternal'), 1),\n",
              " (('eternal', 'wrong'), 1),\n",
              " (('wrong', 'dear'), 1),\n",
              " (('dear', 'sirji'), 1),\n",
              " (('sirji', 'perfectly'), 1),\n",
              " (('perfectly', 'fine'), 1),\n",
              " (('fine', 'indian'), 1),\n",
              " (('indian', 'people'), 1),\n",
              " (('people', '<eos>'), 1),\n",
              " (('impressive', 'godrej'), 1),\n",
              " (('godrej', 'tata'), 1),\n",
              " (('tata', 'complimenting'), 1),\n",
              " (('complimenting', 'hoping'), 1),\n",
              " (('hoping', 'gets'), 1),\n",
              " (('gets', 'second'), 1),\n",
              " (('second', 'term'), 1),\n",
              " (('term', '<eos>'), 1),\n",
              " (('maid', 'saying'), 1),\n",
              " (('saying', 'rahul'), 1),\n",
              " (('rahul', 'keeps'), 1),\n",
              " (('keeps', 'saying'), 1),\n",
              " (('saying', 'modi'), 1),\n",
              " (('modi', 'kalla'), 1),\n",
              " (('kalla', 'yet'), 1),\n",
              " (('yet', 'goes'), 1),\n",
              " (('goes', 'hugs'), 1),\n",
              " (('hugs', 'winks'), 1),\n",
              " (('winks', 'magand'), 1),\n",
              " (('magand', 'idu'), 1),\n",
              " (('idu', 'bekagittu'), 1),\n",
              " (('bekagittu', '<eos>'), 1),\n",
              " (('please', 'vote'), 1),\n",
              " (('modi', 'congress'), 1),\n",
              " (('congress', 'trying'), 1),\n",
              " (('trying', 'divide'), 1),\n",
              " (('divide', 'india'), 1),\n",
              " (('yes', 'good'), 1),\n",
              " (('good', 'job'), 1),\n",
              " (('job', 'highly'), 1),\n",
              " (('highly', 'insensitivearrogant'), 1),\n",
              " (('insensitivearrogant', 'incompetent'), 1),\n",
              " (('incompetent', 'ploar'), 1),\n",
              " (('ploar', 'needs'), 1),\n",
              " (('needs', 'defeated'), 1),\n",
              " (('defeated', 'costnobody'), 1),\n",
              " (('costnobody', 'knows'), 1),\n",
              " (('knows', 'made'), 1),\n",
              " (('made', 'arrogant'), 1),\n",
              " (('arrogant', 'person'), 1),\n",
              " (('person', 'minister'), 1),\n",
              " (('minister', 'gave'), 1),\n",
              " (('gave', 'tickethe'), 1),\n",
              " (('tickethe', 'touch'), 1),\n",
              " (('touch', 'grounddespite'), 1),\n",
              " (('grounddespite', '3months'), 1),\n",
              " (('3months', 'upsc'), 1),\n",
              " (('upsc', 'protests'), 1),\n",
              " (('protests', 'nvr'), 1),\n",
              " (('nvr', 'met'), 1),\n",
              " (('met', '<eos>'), 1),\n",
              " (('2014', 'hindustan'), 1),\n",
              " (('hindustan', 'seen'), 1),\n",
              " (('seen', 'worst'), 1),\n",
              " (('worst', 'hindus'), 1),\n",
              " (('hindus', 'maj'), 1),\n",
              " (('maj', 'hindu'), 1),\n",
              " (('hindu', 'rashtra'), 1),\n",
              " (('rashtra', 'thrashed'), 1),\n",
              " (('thrashed', 'rascal'), 1),\n",
              " (('rascal', 'faces'), 1),\n",
              " (('faces', 'anti'), 1),\n",
              " (('anti', 'indian'), 1),\n",
              " (('indian', 'politiciansantinationals'), 1),\n",
              " (('politiciansantinationals', 'urban'), 1),\n",
              " (('urban', 'naxals'), 1),\n",
              " (('naxals', 'wait'), 1),\n",
              " (('wait', 'watch'), 1),\n",
              " (('watch', 'modis'), 1),\n",
              " (('modis', 'win'), 1),\n",
              " (('win', 'pakistan'), 1),\n",
              " (('pakistan', 'mein'), 1),\n",
              " (('mein', 'bhi'), 1),\n",
              " (('bhi', 'hindu'), 1),\n",
              " (('hindu', 'hona'), 1),\n",
              " (('hona', 'garv'), 1),\n",
              " (('garv', 'baat'), 1),\n",
              " (('baat', 'hogi'), 1),\n",
              " (('hogi', '<eos>'), 1),\n",
              " (('higher', 'voting'), 1),\n",
              " (('voting', 'turnout'), 1),\n",
              " (('turnout', 'directly'), 1),\n",
              " (('directly', 'proportional'), 1),\n",
              " (('proportional', 'bjp'), 1),\n",
              " (('bjp', 'victory'), 1),\n",
              " (('victory', 'wonder'), 1),\n",
              " (('wonder', 'modi'), 1),\n",
              " (('modi', 'launched'), 1),\n",
              " (('launched', 'campaigns'), 1),\n",
              " (('campaigns', 'like'), 1),\n",
              " (('like', 'dont'), 1),\n",
              " (('dont', 'sit'), 1),\n",
              " (('sit', 'home'), 1),\n",
              " (('home', 'ensure'), 1),\n",
              " (('ensure', 'everyone'), 1),\n",
              " (('everyone', 'friends'), 1),\n",
              " (('friends', 'family'), 1),\n",
              " (('family', 'relatives'), 1),\n",
              " (('relatives', 'votes'), 1),\n",
              " (('votes', 'never'), 1),\n",
              " (('never', '<eos>'), 1),\n",
              " (('govt', 'done'), 1),\n",
              " (('done', 'remarkable'), 1),\n",
              " (('remarkable', 'job'), 1),\n",
              " (('job', 'making'), 1),\n",
              " (('making', 'corruption'), 1),\n",
              " (('india', 'ultimate'), 1),\n",
              " (('ultimate', 'success'), 1),\n",
              " (('success', 'shall'), 1),\n",
              " (('shall', 'achieved'), 1),\n",
              " (('achieved', 'corrupt'), 1),\n",
              " (('corrupt', 'jailed'), 1),\n",
              " (('jailed', 'modi'), 1),\n",
              " (('govts', 'vision'), 1),\n",
              " (('vision', 'corruptionfree'), 1),\n",
              " (('corruptionfree', 'india'), 1),\n",
              " (('india', 'ensuring'), 1),\n",
              " (('ensuring', 'looted'), 1),\n",
              " (('looted', 'country'), 1),\n",
              " (('country', 'facing'), 1),\n",
              " (('facing', 'law'), 1),\n",
              " (('law', 'via'), 1),\n",
              " (('use', 'beg'), 1),\n",
              " (('beg', 'campaign'), 1),\n",
              " (('welfare', 'delivery'), 1),\n",
              " (('delivery', 'gst'), 1),\n",
              " (('gst', 'ibc'), 1),\n",
              " (('ibc', 'feo'), 1),\n",
              " (('feo', 'place'), 1),\n",
              " (('place', 'modi'), 1),\n",
              " (('modi', 'exit'), 1),\n",
              " (('psus', '2nd'), 1),\n",
              " (('2nd', 'term'), 1),\n",
              " (('term', 'use'), 1),\n",
              " (('use', 'money'), 1),\n",
              " (('money', 'appoint'), 1),\n",
              " (('appoint', 'judges'), 1),\n",
              " (('judges', 'police'), 1),\n",
              " (('police', 'forensic'), 1),\n",
              " (('forensic', 'labs'), 1),\n",
              " (('labs', 'fasttrack'), 1),\n",
              " (('fasttrack', 'delivery'), 1),\n",
              " (('delivery', 'justice'), 1),\n",
              " (('justice', 'education'), 1),\n",
              " (('education', 'healthcare'), 1),\n",
              " (('healthcare', 'citizens'), 1),\n",
              " (('citizens', 'invest'), 1),\n",
              " (('invest', 'defence'), 1),\n",
              " (('defence', 'india'), 1),\n",
              " (('india', 'well'), 1),\n",
              " (('well', '<eos>'), 1),\n",
              " (('modi', 'trying'), 1),\n",
              " (('trying', 'build'), 1),\n",
              " (('build', 'leaders'), 1),\n",
              " (('leaders', 'party'), 1),\n",
              " (('party', 'live'), 1),\n",
              " (('live', 'deplorable'), 1),\n",
              " (('deplorable', 'characters'), 1),\n",
              " (('characters', '<eos>'), 1),\n",
              " (('overpromise', 'underdelivery'), 1),\n",
              " (('underdelivery', 'pithy'), 1),\n",
              " (('pithy', 'summary'), 1),\n",
              " (('summary', 'economic'), 1),\n",
              " (('economic', 'outcome'), 1),\n",
              " (('outcome', 'last'), 1),\n",
              " (('last', 'five'), 1),\n",
              " (('five', 'years'), 1),\n",
              " (('years', 'approach'), 1),\n",
              " (('approach', 'general'), 1),\n",
              " (('general', 'election'), 1),\n",
              " (('election', '<eos>'), 1),\n",
              " (('healing', 'touch'), 1),\n",
              " (('touch', 'india'), 1),\n",
              " (('india', 'need'), 1),\n",
              " (('need', 'surgery'), 1),\n",
              " (('surgery', 'remove'), 1),\n",
              " (('remove', 'cancer'), 1),\n",
              " (('cancer', 'spread'), 1),\n",
              " (('spread', 'modi'), 1),\n",
              " (('rss', '<eos>'), 1),\n",
              " (('farmers', 'welfare'), 1),\n",
              " (('welfare', '474'), 1),\n",
              " (('474', 'farmers'), 1),\n",
              " (('farmers', 'get'), 1),\n",
              " (('get', 'second'), 1),\n",
              " (('second', 'installment'), 1),\n",
              " (('installment', 'next'), 1),\n",
              " (('next', 'month'), 1),\n",
              " (('month', 'centre'), 1),\n",
              " (('centre', 'announced'), 1),\n",
              " (('announced', '75000crore'), 1),\n",
              " (('75000crore', 'scheme'), 1),\n",
              " (('scheme', '<eos>'), 1),\n",
              " (('mistry', 'man'), 1),\n",
              " (('man', 'drag'), 1),\n",
              " (('drag', 'modi'), 1),\n",
              " (('modi', 'nri'), 1),\n",
              " (('nri', 'followers'), 1),\n",
              " (('followers', 'man'), 1),\n",
              " (('man', 'wrong'), 1),\n",
              " (('wrong', 'action'), 1),\n",
              " (('action', 'taken'), 1),\n",
              " (('taken', 'spreading'), 1),\n",
              " (('spreading', 'hatred'), 1),\n",
              " (('hatred', 'please'), 1),\n",
              " (('please', 'agenda'), 1),\n",
              " (('agenda', 'condemning'), 1),\n",
              " (('condemning', 'criminal'), 1),\n",
              " (('criminal', 'activities'), 1),\n",
              " (('activities', 'sir'), 1),\n",
              " (('sir', 'fyi'), 1),\n",
              " (('fyi', 'please'), 1),\n",
              " (('please', '<eos>'), 1),\n",
              " (('think', 'forgot'), 1),\n",
              " (('forgot', 'dollar'), 1),\n",
              " (('dollar', 'india'), 1),\n",
              " (('india', 'handled'), 1),\n",
              " (('handled', 'exceptionally'), 1),\n",
              " (('exceptionally', 'well'), 1),\n",
              " (('well', 'one'), 1),\n",
              " (('one', 'diplomatic'), 1),\n",
              " (('diplomatic', 'shrewdness'), 1),\n",
              " (('shrewdness', 'achievement'), 1),\n",
              " (('achievement', 'always'), 1),\n",
              " (('always', 'undermine'), 1),\n",
              " (('undermine', 'modi'), 1),\n",
              " (('government', 'always'), 1),\n",
              " (('always', 'prone'), 1),\n",
              " (('prone', 'criticise'), 1),\n",
              " (('criticise', 'even'), 1),\n",
              " (('even', 'without'), 1),\n",
              " (('without', 'considering'), 1),\n",
              " (('considering', 'aspects'), 1),\n",
              " (('aspects', '<eos>'), 1),\n",
              " (('entrepreneurs', 'rising'), 1),\n",
              " (('rising', 'india'), 1),\n",
              " (('govt', 'created'), 1),\n",
              " (('created', 'system'), 1),\n",
              " (('system', 'took'), 1),\n",
              " (('took', 'care'), 1),\n",
              " (('care', 'tax'), 1),\n",
              " (('tax', 'concerns'), 1),\n",
              " (('concerns', 'created'), 1),\n",
              " (('created', 'infra'), 1),\n",
              " (('infra', 'incubate'), 1),\n",
              " (('incubate', 'well'), 1),\n",
              " (('well', 'never'), 1),\n",
              " (('never', 'happened'), 1),\n",
              " (('happened', 'congress'), 1),\n",
              " (('congress', 'guys'), 1),\n",
              " (('guys', 'want'), 1),\n",
              " (('want', 'power'), 1),\n",
              " (('power', 'sit'), 1),\n",
              " (('sit', 'shit'), 1),\n",
              " (('shit', 'simple'), 1),\n",
              " (('simple', '<eos>'), 1),\n",
              " (('nothing', 'else'), 1),\n",
              " (('else', 'modi'), 1),\n",
              " (('modi', 'phobia'), 1),\n",
              " (('phobia', '<eos>'), 1),\n",
              " (('itna', 'fark'), 1),\n",
              " (('fark', '<eos>'), 1),\n",
              " (('government', 'modi'), 1),\n",
              " (('govts', 'efforts'), 1),\n",
              " (('efforts', 'last'), 1),\n",
              " (('last', 'years'), 1),\n",
              " (('governance', 'reforms'), 1),\n",
              " (('reforms', 'institutionalise'), 1),\n",
              " (('institutionalise', 'honesty'), 1),\n",
              " (('honesty', 'way'), 1),\n",
              " (('way', 'every'), 1),\n",
              " (('every', 'system'), 1),\n",
              " (('system', 'institution'), 1),\n",
              " (('institution', 'designed'), 1),\n",
              " (('designed', 'inculcate'), 1),\n",
              " (('inculcate', 'well'), 1),\n",
              " (('well', 'inspire'), 1),\n",
              " (('inspire', 'honesty'), 1),\n",
              " (('honesty', '<eos>'), 1),\n",
              " (('sir', 'namo'), 1),\n",
              " (('namo', 'jai'), 1),\n",
              " (('jai', 'hind'), 1),\n",
              " (('hind', 'jai'), 1),\n",
              " (('jai', 'modi'), 1),\n",
              " (('modi', 'muje'), 1),\n",
              " (('muje', 'puri'), 1),\n",
              " (('puri', 'bharat'), 1),\n",
              " (('bharat', 'janta'), 1),\n",
              " (('janta', 'par'), 1),\n",
              " (('par', 'vishwas'), 1),\n",
              " (('vishwas', 'hai'), 1),\n",
              " (('hai', 'sir'), 1),\n",
              " (('sir', 'aap'), 1),\n",
              " (('aap', 'hamre'), 1),\n",
              " (('hamre', 'prime'), 1),\n",
              " (('minister', 'honge'), 1),\n",
              " (('honge', 'future'), 1),\n",
              " (('future', 'country'), 1),\n",
              " (('country', 'future'), 1),\n",
              " (('future', 'must'), 1),\n",
              " (('must', 'prime'), 1),\n",
              " (('minister', 'bjp'), 1),\n",
              " (('bjp', '<eos>'), 1),\n",
              " (('anchor', 'canvas'), 1),\n",
              " (('canvas', 'modi'), 1),\n",
              " (('modi', 'fit'), 1),\n",
              " (('fit', 'journalism'), 1),\n",
              " (('journalism', '<eos>'), 1),\n",
              " (('slams', 'makers'), 1),\n",
              " (('makers', 'biopic'), 1),\n",
              " (('biopic', 'deliberately'), 1),\n",
              " (('deliberately', 'using'), 1),\n",
              " (('using', 'name'), 1),\n",
              " (('name', 'credit'), 1),\n",
              " (('credit', '<eos>'), 1),\n",
              " (('channels', 'say'), 1),\n",
              " (('say', 'modi'), 1),\n",
              " (('also', 'scared'), 1),\n",
              " (('scared', 'contests'), 1),\n",
              " (('contests', 'two'), 1),\n",
              " (('two', 'seats'), 1),\n",
              " (('seats', 'even'), 1),\n",
              " (('even', 'propoganda'), 1),\n",
              " (('propoganda', 'needs'), 1),\n",
              " (('needs', 'little'), 1),\n",
              " (('little', 'decency'), 1),\n",
              " (('decency', '<eos>'), 1),\n",
              " (('', 'new'), 1),\n",
              " (('india', 'indias'), 1),\n",
              " (('indias', 'century'), 1),\n",
              " (('century', 'yuva'), 1),\n",
              " (('yuva', 'shakti'), 1),\n",
              " (('shakti', 'take'), 1),\n",
              " (('take', 'great'), 1),\n",
              " (('great', 'heights'), 1),\n",
              " (('heights', 'modi'), 1),\n",
              " (('govt', 'stands'), 1),\n",
              " (('stands', 'firmly'), 1),\n",
              " (('firmly', 'via'), 1),\n",
              " (('100', 'sure'), 1),\n",
              " (('sure', 'sir'), 1),\n",
              " (('sir', 'inform'), 1),\n",
              " (('inform', 'family'), 1),\n",
              " (('family', 'friends'), 1),\n",
              " (('friends', 'give'), 1),\n",
              " (('give', 'record'), 1),\n",
              " (('record', 'numbers'), 1),\n",
              " (('numbers', 'vote'), 1),\n",
              " (('modi', 'sir'), 1),\n",
              " (('sir', 'bjp'), 1),\n",
              " (('bjp', 'thanks'), 1),\n",
              " (('thanks', '<eos>'), 1),\n",
              " (('loose', 'existance'), 1),\n",
              " (('existance', 'election'), 1),\n",
              " (('election', 'rafel'), 1),\n",
              " (('rafel', 'corruption'), 1),\n",
              " (('free', 'scam'), 1),\n",
              " (('scam', 'free'), 1),\n",
              " (('free', 'nation'), 1),\n",
              " (('nation', 'know'), 1),\n",
              " (('know', 'nature'), 1),\n",
              " (('nature', 'except'), 1),\n",
              " (('except', 'narendra'), 1),\n",
              " (('party', 'scammer'), 1),\n",
              " (('scammer', 'aap'), 1),\n",
              " (('aap', 'nautanki'), 1),\n",
              " (('nautanki', 'baj'), 1),\n",
              " (('baj', '<eos>'), 1),\n",
              " (('concierge', 'super'), 1),\n",
              " (('super', 'rich'), 1),\n",
              " (('rich', 'makes'), 1),\n",
              " (('makes', 'unusual'), 1),\n",
              " (('unusual', 'sight'), 1),\n",
              " (('sight', 'nirav'), 1),\n",
              " (('nirav', 'modis'), 1),\n",
              " (('modis', 'hearing'), 1),\n",
              " (('hearing', 'via'), 1),\n",
              " (('', 'confused'), 1),\n",
              " (('confused', 'said'), 1),\n",
              " (('said', 'intellectuals'), 1),\n",
              " (('intellectuals', 'decide'), 1),\n",
              " (('decide', 'modi'), 1),\n",
              " (('modi', 'policies'), 1),\n",
              " (('question', 'intellectuals'), 1),\n",
              " (('intellectuals', 'sided'), 1),\n",
              " (('sided', 'modi'), 1),\n",
              " (('modi', 'similarly'), 1),\n",
              " (('similarly', 'disagree'), 1),\n",
              " (('disagree', 'policies'), 1),\n",
              " (('question', 'deciding'), 1),\n",
              " (('deciding', 'anything'), 1),\n",
              " (('anything', '<eos>'), 1),\n",
              " (('asked', 'learn'), 1),\n",
              " (('learn', 'treat'), 1),\n",
              " (('treat', 'minority'), 1),\n",
              " (('minority', 'well'), 1),\n",
              " (('well', 'want'), 1),\n",
              " (('want', 'minor'), 1),\n",
              " (('minor', '<eos>'), 1),\n",
              " (('india', 'vote'), 1),\n",
              " (('vote', 'shri'), 1),\n",
              " (('', 'modi'), 1),\n",
              " (('govts', 'years'), 1),\n",
              " (('years', 'cheating'), 1),\n",
              " (('cheating', 'people'), 1),\n",
              " (('people', 'promises'), 1),\n",
              " (('promises', 'impacted'), 1),\n",
              " (('impacted', 'lot'), 1),\n",
              " (('lot', 'things'), 1),\n",
              " (('things', 'economy'), 1),\n",
              " (('economy', 'country'), 1),\n",
              " (('country', 'brotherhood'), 1),\n",
              " (('brotherhood', 'nation'), 1),\n",
              " (('nation', '<eos>'), 1),\n",
              " (('logic', 'sir'), 1),\n",
              " (('sir', 'could'), 1),\n",
              " (('could', 'please'), 1),\n",
              " (('please', 'throw'), 1),\n",
              " (('throw', 'light'), 1),\n",
              " (('light', 'logic'), 1),\n",
              " (('logic', 'behind'), 1),\n",
              " (('behind', 'tweet'), 1),\n",
              " (('tweet', 'bjpnda'), 1),\n",
              " (('bjpnda', 'lose'), 1),\n",
              " (('lose', 'modi'), 1),\n",
              " (('modi', 'fights'), 1),\n",
              " (('fights', 'bengaluru'), 1),\n",
              " (('bengaluru', 'south'), 1),\n",
              " (('south', '<eos>'), 1),\n",
              " (('modi', 'opposition'), 1),\n",
              " (('opposition', 'opposition'), 1),\n",
              " (('opposition', 'leaders'), 1),\n",
              " (('leaders', 'intent'), 1),\n",
              " (('intent', 'clear'), 1),\n",
              " (('clear', 'dont'), 1),\n",
              " (('dont', 'understand'), 1),\n",
              " (('understand', 'failing'), 1),\n",
              " (('failing', 'attempt'), 1),\n",
              " (('attempt', 'vote'), 1),\n",
              " (('modi', 'telling'), 1),\n",
              " (('telling', 'people'), 1),\n",
              " (('people', 'come'), 1),\n",
              " (('come', 'power'), 1),\n",
              " (('power', '<eos>'), 1),\n",
              " (('great', 'opponents'), 1),\n",
              " (('opponents', 'generally'), 1),\n",
              " (('generally', 'selfish'), 1),\n",
              " (('selfish', 'idiots'), 1),\n",
              " (('idiots', 'keep'), 1),\n",
              " (('keep', 'attacking'), 1),\n",
              " (('attacking', 'governance'), 1),\n",
              " (('governance', 'skill'), 1),\n",
              " (('skill', 'modi'), 1),\n",
              " (('great', '3040'), 1),\n",
              " (('3040', 'yrs'), 1),\n",
              " (('yrs', 'tell'), 1),\n",
              " (('tell', 'give'), 1),\n",
              " (('give', 'oppo'), 1),\n",
              " (('oppo', 'know'), 1),\n",
              " (('know', 'years'), 1),\n",
              " (('years', 'modi'), 1),\n",
              " (('modi', 'rule'), 1),\n",
              " (('rule', 'wonders'), 1),\n",
              " (('wonders', 'stupid'), 1),\n",
              " (('stupid', 'world'), 1),\n",
              " (('world', 'created'), 1),\n",
              " (('created', 'dishonest'), 1),\n",
              " (('dishonest', '<eos>'), 1),\n",
              " (('pit', 'pictures'), 1),\n",
              " (('pictures', 'videos'), 1),\n",
              " (('videos', 'hindu'), 1),\n",
              " (('hindu', 'extremist'), 1),\n",
              " (('extremist', 'crime'), 1),\n",
              " (('crime', 'years'), 1),\n",
              " (('years', 'use'), 1),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def topWords(keytuple,value,sentiment=\"\", color='gray', top=10):\n",
        "  key = [','.join(ngram) for ngram in keytuple]\n",
        "  plt.figure(1,figsize=(16,4))\n",
        "  plt.bar(key[:top],value[:top], color =color,\n",
        "          width = 0.4)\n",
        "  plt.xlabel(sentiment)\n",
        "  plt.ylabel(\"Count\")\n",
        "  plt.title(\"Top \"+str(top)+\" words\")\n",
        "  plt.show()\n",
        "\n",
        "topWords(dfgram[0],dfgram[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "HIKS5fSPbPcA",
        "outputId": "e83ffbb1-5e8b-49b5-f344-8f175a712b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateChances(keytuple,dataset,n=2):\n",
        "  chance = {}\n",
        "  idxn = len(keytuple) - n + 1\n",
        "  ngram = N_Grams(dataset,n,dataframe=False)\n",
        "  #print(ngram)\n",
        "  for ng in ngram :\n",
        "    match = True\n",
        "    for i in range(n-1):\n",
        "      #print(keytuple[idxn+i], ng[0][i])\n",
        "      #print(len(keytuple),idxn, i, idxn+i)\n",
        "      if keytuple[idxn+i] != ng[0][i]:\n",
        "        match = False\n",
        "        break\n",
        "    #print(keytuple,ng[0],keytuple in ng[0])\n",
        "    if match :\n",
        "      #print(keytuple,ng[0])\n",
        "    #if keytuple in ng[0]:\n",
        "      #print(ng[1],len(ngram),ng[1]/len(ngram))\n",
        "      chance[ng[0][len(ng[0])-1]] = ng[1]/len(ngram)\n",
        "\n",
        "  return chance\n",
        "\n",
        "calculateChances((\"narendra\", \"modi\"),arr[:100],3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fwYAOV2bVFu",
        "outputId": "b62a6114-5817-46c8-9b50-b19e4accf530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<eos>': 0.0007662835249042146,\n",
              " 'amit': 0.0007662835249042146,\n",
              " 'appeals': 0.0007662835249042146,\n",
              " 'become': 0.0007662835249042146,\n",
              " 'bjp': 0.0015325670498084292,\n",
              " 'brothers': 0.0007662835249042146,\n",
              " 'producer': 0.0007662835249042146}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(keytuple,dataset, n=2):\n",
        "  while 1:\n",
        "    chances = calculateChances(keytuple,dataset,n)\n",
        "    lkey = list(keytuple)\n",
        "    #print(lkey)\n",
        "    try:\n",
        "      wordpath = max(chances, key=chances.get)\n",
        "      #print(wordpath)\n",
        "      #lkey.append(wordpath)\n",
        "      if wordpath == \"\" or wordpath == \"<eos>\":\n",
        "        print(\"Predict sentence:\",' '.join(keytuple))\n",
        "        break\n",
        "\n",
        "      lkey.append(wordpath)\n",
        "      print(' '.join(keytuple))\n",
        "    except:\n",
        "      break\n",
        "    keytuple = tuple(lkey)\n",
        "\n",
        "predict((\"narendra\", \"modi\"),arr[:100],3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Uq1iNvy_tA",
        "outputId": "6f67b6f2-7ad3-4e24-d720-ebf93265cdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "narendra modi\n",
            "narendra modi bjp\n",
            "Predict sentence: narendra modi bjp party\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictSentence(sentence,dataset,n=2):\n",
        "  text = sentence.replace(\"RT \", \"\")\n",
        "  text = text.replace(\"RT\", \"\")\n",
        "  text = re.sub(r'[^\\w\\s]','',text)\n",
        "  text = re.sub('\\\\s+', ' ', text).lower()\n",
        "  words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]\n",
        "  kt = tuple(words)\n",
        "  predict(kt,dataset,n)\n",
        "\n",
        "predictSentence(\"narendra modi\",arr[:100],3)"
      ],
      "metadata": {
        "id": "Xaf5ZVwU2gAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f673db-2ffa-48e8-c1d3-c8bfe24957b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "narendra modi\n",
            "narendra modi bjp\n",
            "Predict sentence: narendra modi bjp party\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NEURAL LANGUAGE MODEL"
      ],
      "metadata": {
        "id": "usscc4TQR4Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "source : https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/"
      ],
      "metadata": {
        "id": "-NAufUr0R_f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "metadata": {
        "id": "3o-HvFQuR8Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "-9bBZjWzAJT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88bf6f2-1ec1-44ae-d016-17d14dea551d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='Do not let the day end without having grown a little,'\n",
        "def wordProcess(sentence):\n",
        "  text = sentence.replace(\"RT \", \"\")\n",
        "  text = text.replace(\"RT\", \"\")\n",
        "  text = re.sub(r'[^\\w\\s]','',text)\n",
        "  text = re.sub('\\\\s+', ' ', text).lower()\n",
        "  return [word for word in text.split(\" \")]\n",
        "wordProcess(sentence)"
      ],
      "metadata": {
        "id": "qb9Xv-bsDStz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7eb5af2-659f-4996-bc2b-1d54b2758406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do',\n",
              " 'not',\n",
              " 'let',\n",
              " 'the',\n",
              " 'day',\n",
              " 'end',\n",
              " 'without',\n",
              " 'having',\n",
              " 'grown',\n",
              " 'a',\n",
              " 'little']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = twitter.apply(lambda row: row['clean_text'], axis=1)[:100]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2dOEyu2E9Dp",
        "outputId": "2f607607-9a51-421c-9ae3-0134d0eb0770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     when modi promised “minimum government maximum...\n",
              "1     talk all the nonsense and continue all the dra...\n",
              "2     what did just say vote for modi  welcome bjp t...\n",
              "3     asking his supporters prefix chowkidar their n...\n",
              "4     answer who among these the most powerful world...\n",
              "                            ...                        \n",
              "95    country prospers when the women the country ar...\n",
              "96                 sabbash mera vote for peppermit abvp\n",
              "97    yogi adityanath hold 100 rallies seek votes fo...\n",
              "98    from the very beginningmodi doing wada faramos...\n",
              "99    modi politics hate modiji loves india modiji w...\n",
              "Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vocabList(sentences):\n",
        "  vocabs = {}\n",
        "  i = 1\n",
        "  for row in sentences:\n",
        "    for word in wordProcess(row):\n",
        "      if vocabs.get(word) == None:\n",
        "        vocabs[word] = i\n",
        "        i += 1\n",
        "  return vocabs\n",
        "\n",
        "vocabs = vocabList(tokens)\n",
        "print('Vocabulary Size: %d' % len(vocabs))\n",
        "print(vocabs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHUKOV6LBphQ",
        "outputId": "5750b8bc-bbf5-43ba-ebd0-3aae82ebebc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 970\n",
            "{'when': 1, 'modi': 2, 'promised': 3, 'minimum': 4, 'government': 5, 'maximum': 6, 'governance': 7, 'expected': 8, 'him': 9, 'begin': 10, 'the': 11, 'difficult': 12, 'job': 13, 'reforming': 14, 'state': 15, 'why': 16, 'does': 17, 'take': 18, 'years': 19, 'get': 20, 'justice': 21, 'should': 22, 'and': 23, 'not': 24, 'business': 25, 'exit': 26, 'psus': 27, 'temples': 28, 'talk': 29, 'all': 30, 'nonsense': 31, 'continue': 32, 'drama': 33, 'will': 34, 'vote': 35, 'for': 36, '': 37, 'what': 38, 'did': 39, 'just': 40, 'say': 41, 'welcome': 42, 'bjp': 43, 'told': 44, 'you': 45, 'rahul': 46, 'main': 47, 'campaigner': 48, 'think': 49, 'relax': 50, 'asking': 51, 'his': 52, 'supporters': 53, 'prefix': 54, 'chowkidar': 55, 'their': 56, 'names': 57, 'great': 58, 'service': 59, 'now': 60, 'there': 61, 'confusion': 62, 'read': 63, 'crustal': 64, 'clear': 65, 'crass': 66, 'filthy': 67, 'nonsensical': 68, 'see': 69, 'how': 70, 'most': 71, 'abuses': 72, 'are': 73, 'coming': 74, 'from': 75, 'chowkidars': 76, 'answer': 77, 'who': 78, 'among': 79, 'these': 80, 'powerful': 81, 'world': 82, 'leader': 83, 'today': 84, 'trump': 85, 'putin': 86, 'may': 87, 'kiya': 88, 'tho': 89, 'refresh': 90, 'maarkefir': 91, 'comment': 92, 'karo': 93, 'surat': 94, 'women': 95, 'perform': 96, 'yagna': 97, 'seeks': 98, 'divine': 99, 'grace': 100, 'narendra': 101, 'become': 102, 'again': 103, 'this': 104, 'comes': 105, 'cabinet': 106, 'which': 107, 'has': 108, 'scholars': 109, 'like': 110, 'smriti': 111, 'hema': 112, 'time': 113, 'introspect': 114, 'with': 115, 'upcoming': 116, 'election': 117, 'india': 118, 'saga': 119, 'going': 120, 'important': 121, 'pair': 122, 'look': 123, 'current': 124, 'leads': 125, 'govt': 126, 'elected': 127, 'deal': 128, 'brexit': 129, 'combination': 130, 'weekly': 131, 'looks': 132, 'juicy': 133, 'bears': 134, 'imho': 135, 'gandhi': 136, 'was': 137, 'gay': 138, 'things': 139, 'demonetisation': 140, 'gst': 141, 'goods': 142, 'services': 143, 'taxthe': 144, 'upper': 145, 'castes': 146, 'would': 147, 'sort': 148, 'either': 149, 'view': 150, 'favourably': 151, 'that': 152, 'need': 153, 'give': 154, 'more': 155, 'other': 156, 'dalits': 157, 'muslims': 158, 'were': 159, 'against': 160, 'because': 161, 'constituency2': 162, 'hope': 163, 'tuthukudi': 164, 'people': 165, 'prefer': 166, 'honest': 167, 'well': 168, 'behaved': 169, 'nationalist': 170, 'courageous': 171, 'likly': 172, 'minister': 173, 'benifit': 174, 'thuthukudi': 175, 'calm': 176, 'waters': 177, 'wheres': 178, 'wave': 179, 'one': 180, 'can': 181, 'make': 182, 'difference': 183, 'anil': 184, 'kapoor': 185, 'answers': 186, 'modis': 187, '2019': 188, 'clarion': 189, 'call': 190, 'extends': 191, 'support': 192, 'kar': 193, 'campaign': 194, 'such': 195, 'party': 196, 'leadershipwho': 197, 'fast': 198, 'firm': 199, 'action': 200, 'none': 201, 'than': 202, 'damodardas': 203, 'created': 204, 'jobs': 205, 'through': 206, 'our': 207, 'ensure': 208, 'deserve': 209, 'anupam': 210, 'kher': 211, 'responds': 212, 'appeal': 213, 'elections': 214, 'dont': 215, 'play': 216, 'words': 217, 'talking': 218, 'about': 219, 'swamy': 220, 'relation': 221, 'guru': 222, 'saying': 223, 'good': 224, 'protecting': 225, 'mind': 226, 'tweeted': 227, 'dark': 228, 'side': 229, 'terrorism': 230, 'any': 231, 'brighter': 232, 'better': 233, 'know': 234, 'didn': 235, 'write': 236, 'mean': 237, 'anti': 238, 'try': 239, 'visit': 240, 'plz': 241, 'haven': 242, 'used': 243, 'recently': 244, 'said': 245, 'national': 246, 'put': 247, 'gen': 248, 'hooda': 249, 'congress': 250, 'those': 251, 'jawans': 252, 'hear': 253, 'belief': 254, 'leadership': 255, 'shri': 256, 'entering': 257, 'into': 258, 'politics': 259, 'given': 260, 'form': 261, 'file': 262, 'nomination': 263, 'khammam': 264, 'parliamentary': 265, 'seat': 266, 'proceeding': 267, 'crush': 268, 'jaws': 269, 'shoutmodimodi': 270, 'says': 271, 'jds': 272, 'mla': 273, 'inciting': 274, 'murder': 275, 'sultanpur': 276, 'uttar': 277, 'pradesh': 278, 'loksabha': 279, 'candidate': 280, 'select': 281, 'pawan': 282, 'kumar': 283, 'pandey': 284, 'actually': 285, 'public': 286, 'want': 287, 'but': 288, 'your': 289, 'condidate': 290, 'popular': 291, 'district': 292, 'bsp': 293, 'sonbhadra': 294, 'singh': 295, 'thiugh': 296, 'nehru': 297, 'alive': 298, 'still': 299, 'heart': 300, 'every': 301, 'failure': 302, 'responsible': 303, 'development': 304, 'mass': 305, 'movement': 306, 'under': 307, 'economic': 308, 'social': 309, 'political': 310, 'empowerment': 311, 'life': 312, 'witnessed': 313, 'positive': 314, 'paradigm': 315, 'shift': 316, 'new': 317, 'already': 318, 'taken': 319, 'notice': 320, 'ordered': 321, 'probe': 322, 'muslim': 323, 'family': 324, 'being': 325, 'harassed': 326, 'beaten': 327, 'extremist': 328, 'hindus': 329, 'suggested': 330, 'leave': 331, 'move': 332, 'pakistan': 333, 'waiting': 334, 'also': 335, 'varanasi': 336, 'according': 337, 'yogi': 338, 'imran': 339, 'masood': 340, 'kin': 341, 'azhar': 342, 'logic': 343, 'nirav': 344, 'lalit': 345, 'brothers': 346, 'same': 347, 'mother': 348, 'agree': 349, 'only': 350, 'during': 351, 'tenure': 352, 'modiganga': 353, 'rejuvenation': 354, 'works': 355, 'have': 356, 'started': 357, 'working': 358, 'three': 359, 'codes': 360, 'cracked': 361, 'huge': 362, 'foreign': 363, 'policy': 364, 'jumpstart': 365, 'via': 366, 'govts': 367, 'slashing': 368, 'indias': 369, 'education': 370, 'budget': 371, 'indicator': 372, 'they': 373, 'care': 374, 'future': 375, 'president': 376, 'hand': 377, 'ensured': 378, 'increase': 379, 'gdp': 380, 'deserves': 381, 'born': 382, 'religion': 383, 'where': 384, 'female': 385, 'deities': 386, 'worshipped': 387, 'its': 388, 'misogynistic': 389, 'sadistic': 390, 'tradition': 391, 'totally': 392, 'point': 393, 'isits': 394, 'man': 395, 'made': 396, 'written': 397, 'religious': 398, 'lunatic': 399, 'own': 400, 'repressive': 401, 'amazedn': 402, 'fear': 403, 'frustation': 404, 'result': 405, 'sir': 406, 'waste': 407, 'ministerdisgrace': 408, 'entire': 409, 'check': 410, 'out': 411, 'latest': 412, 'article': 413, 'premier': 414, 'archery': 415, 'league': 416, 'second': 417, 'optimistic': 418, 'globally': 419, 'executive': 420, 'growth': 421, 'shows': 422, 'survey': 423, 'senior': 424, 'executives': 425, 'number': 426, 'roles': 427, 'year': 428, 'wish': 429, 'vision': 430, 'least': 431, 'interested': 432, 'personal': 433, 'enmity': 434, 'others': 435, 'problem': 436, 'handle': 437, 'personally': 438, 'expect': 439, 'nation': 440, 'join': 441, 'dirty': 442, 'fight': 443, 'tell': 444, 'eternal': 445, 'wrong': 446, 'dear': 447, 'sirji': 448, 'perfectly': 449, 'fine': 450, 'indian': 451, 'impressive': 452, 'godrej': 453, 'tata': 454, 'complimenting': 455, 'hoping': 456, 'gets': 457, 'term': 458, 'maid': 459, 'keeps': 460, 'kalla': 461, 'yet': 462, 'goes': 463, 'hugs': 464, 'winks': 465, 'magand': 466, 'idu': 467, 'bekagittu': 468, 'please': 469, 'trying': 470, 'divide': 471, 'yes': 472, 'highly': 473, 'insensitivearrogant': 474, 'incompetent': 475, 'ploar': 476, 'needs': 477, 'defeated': 478, 'costnobody': 479, 'knows': 480, 'arrogant': 481, 'person': 482, 'gave': 483, 'tickethe': 484, 'touch': 485, 'grounddespite': 486, '3months': 487, 'upsc': 488, 'protests': 489, 'nvr': 490, 'met': 491, 'before': 492, '2014': 493, 'hindustan': 494, 'seen': 495, 'worst': 496, 'maj': 497, 'hindu': 498, 'rashtra': 499, 'thrashed': 500, 'rascal': 501, 'faces': 502, 'politiciansantinationals': 503, 'urban': 504, 'naxals': 505, 'wait': 506, 'watch': 507, 'after': 508, 'win': 509, 'mein': 510, 'bhi': 511, 'hona': 512, 'garv': 513, 'baat': 514, 'hogi': 515, 'higher': 516, 'voting': 517, 'turnout': 518, 'directly': 519, 'proportional': 520, 'victory': 521, 'wonder': 522, 'launched': 523, 'campaigns': 524, 'sit': 525, 'home': 526, 'everyone': 527, 'friends': 528, 'relatives': 529, 'votes': 530, 'never': 531, 'done': 532, 'remarkable': 533, 'making': 534, 'corruption': 535, 'free': 536, 'ultimate': 537, 'success': 538, 'shall': 539, 'achieved': 540, 'corrupt': 541, 'jailed': 542, 'corruptionfree': 543, 'ensuring': 544, 'looted': 545, 'country': 546, 'facing': 547, 'law': 548, 'namo': 549, 'app': 550, 'use': 551, 'beg': 552, 'welfare': 553, 'delivery': 554, 'ibc': 555, 'feo': 556, 'place': 557, '2nd': 558, 'money': 559, 'appoint': 560, 'judges': 561, 'police': 562, 'forensic': 563, 'labs': 564, 'fasttrack': 565, 'healthcare': 566, 'citizens': 567, 'invest': 568, 'defence': 569, 'build': 570, 'leaders': 571, 'live': 572, 'deplorable': 573, 'characters': 574, 'overpromise': 575, 'underdelivery': 576, 'pithy': 577, 'summary': 578, 'outcome': 579, 'last': 580, 'five': 581, 'approach': 582, 'general': 583, 'healing': 584, 'surgery': 585, 'remove': 586, 'cancer': 587, 'spread': 588, 'rss': 589, 'farmers': 590, '474': 591, 'installment': 592, 'next': 593, 'month': 594, 'centre': 595, 'announced': 596, '75000crore': 597, 'scheme': 598, 'mistry': 599, 'then': 600, 'drag': 601, 'nri': 602, 'followers': 603, 'spreading': 604, 'hatred': 605, 'don': 606, 'agenda': 607, 'condemning': 608, 'criminal': 609, 'activities': 610, 'fyi': 611, 'forgot': 612, 'dollar': 613, 'handled': 614, 'exceptionally': 615, 'diplomatic': 616, 'shrewdness': 617, 'achievement': 618, 'always': 619, 'undermine': 620, 'prone': 621, 'criticise': 622, 'even': 623, 'without': 624, 'considering': 625, 'aspects': 626, 'entrepreneurs': 627, 'rising': 628, 'system': 629, 'them': 630, 'took': 631, 'tax': 632, 'concerns': 633, 'infra': 634, 'incubate': 635, 'happened': 636, 'guys': 637, 'power': 638, 'shit': 639, 'simple': 640, 'nothing': 641, 'else': 642, 'phobia': 643, 'itna': 644, 'fark': 645, 'once': 646, 'efforts': 647, 'reforms': 648, 'been': 649, 'institutionalise': 650, 'honesty': 651, 'way': 652, 'institution': 653, 'designed': 654, 'inculcate': 655, 'inspire': 656, 'jai': 657, 'hind': 658, 'muje': 659, 'puri': 660, 'bharat': 661, 'janta': 662, 'par': 663, 'vishwas': 664, 'hai': 665, 'aap': 666, 'hamre': 667, 'prime': 668, 'honge': 669, 'must': 670, 'anchor': 671, 'doing': 672, 'canvas': 673, 'fit': 674, 'journalism': 675, 'slams': 676, 'makers': 677, 'biopic': 678, 'deliberately': 679, 'using': 680, 'name': 681, 'credit': 682, 'channels': 683, 'scared': 684, 'contests': 685, 'two': 686, 'seats': 687, 'propoganda': 688, 'little': 689, 'decency': 690, 'century': 691, 'yuva': 692, 'shakti': 693, 'heights': 694, 'stands': 695, 'firmly': 696, '100': 697, 'sure': 698, 'inform': 699, 'record': 700, 'numbers': 701, 'thanks': 702, 'loose': 703, 'existance': 704, 'rafel': 705, 'scam': 706, 'nature': 707, 'except': 708, 'scammer': 709, 'nautanki': 710, 'baj': 711, 'concierge': 712, 'super': 713, 'rich': 714, 'makes': 715, 'unusual': 716, 'sight': 717, 'hearing': 718, 'confused': 719, 'intellectuals': 720, 'decide': 721, 'policies': 722, 'question': 723, 'sided': 724, 'similarly': 725, 'disagree': 726, 'too': 727, 'deciding': 728, 'anything': 729, 'asked': 730, 'learn': 731, 'treat': 732, 'minority': 733, 'minor': 734, 'over': 735, 'cheating': 736, 'promises': 737, 'impacted': 738, 'lot': 739, 'economy': 740, 'brotherhood': 741, 'could': 742, 'throw': 743, 'some': 744, 'light': 745, 'behind': 746, 'tweet': 747, 'bjpnda': 748, 'lose': 749, 'fights': 750, 'bengaluru': 751, 'south': 752, 'opposition': 753, 'intent': 754, 'understand': 755, 'failing': 756, 'attempt': 757, 'telling': 758, 'come': 759, 'opponents': 760, 'generally': 761, 'selfish': 762, 'idiots': 763, 'keep': 764, 'attacking': 765, 'skill': 766, '3040': 767, 'yrs': 768, 'oppo': 769, 'rule': 770, 'wonders': 771, 'stupid': 772, 'dishonest': 773, 'pit': 774, 'pictures': 775, 'videos': 776, 'crime': 777, 'coz': 778, 'ppl': 779, 'storm': 780, 'terror': 781, 'appeals': 782, 'tweetstorm': 783, 'khans': 784, 'killed': 785, 'paid': 786, 'loan': 787, 'named': 788, 'vijay': 789, 'maalya': 790, 'whose': 791, 'list': 792, 'doesnt': 793, 'false': 794, 'delivered': 795, 'whatever': 796, 'track': 797, 'count': 798, 'kitna': 799, 'jalte': 800, 'tum': 801, 'jealousy': 802, 'towards': 803, 'together': 804, 'tbfree': 805, '2025': 806, 'ever': 807, 'rgis': 808, 'length': 809, 'breadth': 810, 'reception': 811, 'masses': 812, 'love': 813, 'match': 814, 'mad': 815, 'sandip': 816, 'sense': 817, 'javed': 818, 'akhtar': 819, 'called': 820, 'producer': 821, 'ssingh': 822, 'row': 823, 'entertainment': 824, 'news': 825, 'express': 826, 'porn': 827, 'sites': 828, 'banned': 829, 'eat': 830, 'beef': 831, 'biryani': 832, 'sleep': 833, 'asaduddin': 834, 'owaisi': 835, 'voted': 836, 'screwed': 837, 'hate': 838, 'ideology': 839, 'propagated': 840, 'few': 841, 'weeks': 842, 'majority': 843, 'propagandas': 844, 'media': 845, 'fed': 846, 'terrorists': 847, 'bullets': 848, 'bombs': 849, 'adityanath': 850, 'open': 851, 'eyes': 852, 'critic': 853, 'cong': 854, 'exculding': 855, 'mongers': 856, 'vast': 857, 'indai': 858, 'concern': 859, 'security': 860, 'praise': 861, 'worthy': 862, 'autocratic': 863, 'norm': 864, 'denying': 865, 'each': 866, 'allegation': 867, 'kimjong': 868, 'painful': 869, 'sorrowful': 870, 'regards': 871, 'requesting': 872, 'stop': 873, 'giving': 874, 'favor': 875, 'big': 876, 'malya': 877, 'nivav': 878, 'taking': 879, 'nonscene': 880, 'charges': 881, 'face': 882, 'doesn': 883, 'haunt': 884, 'condemn': 885, 'abduction': 886, 'girls': 887, 'wel': 888, 'recorded': 889, 'message': 890, 'unlike': 891, 'treats': 892, 'bank': 893, 'sharam': 894, 'karodesh': 895, 'ghotale': 896, 'bech': 897, 'khaega': 898, 'tumhara': 899, 'youth': 900, 'interest': 901, 'issues': 902, 'judge': 903, 'right': 904, 'forget': 905, 'petrol': 906, 'prices': 907, 'risen': 908, 'gulf': 909, 'down': 910, 'शबच': 911, 'thought': 912, 'petta': 913, 'antibjp': 914, 'movie': 915, 'recent': 916, 'times': 917, 'blog': 918, 'sapna': 919, 'choudhary': 920, 'yesterday': 921, 'her': 922, 'campaigning': 923, 'manoj': 924, 'tiwari': 925, 'superbly': 926, 'summarizedjai': 927, 'vande': 928, 'mataramagain': 929, 'sarkar': 930, 'prospers': 931, 'leading': 932, 'forefront': 933, 'supported': 934, 'endeavour': 935, 'lives': 936, 'focussed': 937, 'enabled': 938, 'empower': 939, 'themselves': 940, 'sabbash': 941, 'mera': 942, 'peppermit': 943, 'abvp': 944, 'hold': 945, 'rallies': 946, 'seek': 947, 'amit': 948, 'shah': 949, 'very': 950, 'beginningmodi': 951, 'wada': 952, 'faramoshi': 953, 'believe': 954, 'example': 955, 'lakhs': 956, 'failed': 957, 'fulfill': 958, 'promise': 959, 'modiji': 960, 'loves': 961, 'hates': 962, 'enemies': 963, 'destroying': 964, 'camp': 965, 'hatedont': 966, 'defame': 967, 'humane': 968, 'kind': 969, 'pure': 970}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encodeSentence(sentence, vocabs):\n",
        "  encode = []\n",
        "  for word in wordProcess(sentence):\n",
        "    encode.append(vocabs.get(word))\n",
        "  return encode\n",
        "\n",
        "def encodeSequence(sentences, vocabs):\n",
        "  sequences = list()\n",
        "  for line in sentences:\n",
        "    encoded = encodeSentence(line, vocabs)\n",
        "    for i in range(1, len(encoded)):\n",
        "      sequence = encoded[:i+1]\n",
        "      sequences.append(sequence)\n",
        "\n",
        "  max_length = max([len(seq) for seq in sequences])\n",
        "  return pad_sequences(sequences, maxlen=max_length, padding='pre'), max_length\n",
        "\n",
        "encoded,max_length = encodeSequence(tokens, vocabs)\n",
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRlwINaCFmuQ",
        "outputId": "6287f9d7-0319-4460-c06b-0f8fef063f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   1,   2],\n",
              "       [  0,   0,   0, ...,   1,   2,   3],\n",
              "       [  0,   0,   0, ...,   2,   3,   4],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 207, 968, 969],\n",
              "       [  0,   0,   0, ..., 968, 969, 970],\n",
              "       [  0,   0,   2, ..., 969, 970, 167]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(encoded)\n",
        "count_vocab = len(vocabs)+1\n",
        "print(sequences)\n",
        "X, y = sequences[:,:-1],sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=count_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKQyKJnQKys_",
        "outputId": "0325c83f-2d2a-4210-bb1c-67931df99129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0   1   2]\n",
            " [  0   0   0 ...   1   2   3]\n",
            " [  0   0   0 ...   2   3   4]\n",
            " ...\n",
            " [  0   0   0 ... 207 968 969]\n",
            " [  0   0   0 ... 968 969 970]\n",
            " [  0   0   2 ... 969 970 167]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a sequence from a language model\n",
        "def predict(model, tokenizer, max_length, seed_text, n_words):\n",
        "  in_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "  for _ in range(n_words):\n",
        "    #in_text = wordProcess(in_text)\n",
        "    # encode the text as integer\n",
        "    print(in_text)\n",
        "    encoded = encodeSentence(in_text, vocabs)\n",
        "\t\t# predict probabilities for each word\n",
        "\t\t#yhat = model.predict_classes(encoded, verbose=0)\n",
        "    #print(encoded)\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "    yhat = (model.predict(encoded) > 0.5).astype(\"int32\")\n",
        "    # map predicted word index to word\n",
        "    out_word = ''\n",
        "    #print(tokenizer.word_index.items(),yhat[0])\n",
        "    #print(yhat[0])\n",
        "    for word, index in vocabs.items():\n",
        "      #print(index,word)\n",
        "      if yhat[0][index] == 1:\n",
        "        out_word = word\n",
        "        break\n",
        "      # append to input\n",
        "    if out_word != '':\n",
        "      in_text += ' ' + out_word\n",
        "  return in_text"
      ],
      "metadata": {
        "id": "iyRwOwjV2_i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(count_vocab, 10, input_length=max_length-1))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(count_vocab, activation='softmax'))\n",
        "# compile network\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSiMhl-g3o69",
        "outputId": "f2f9edc2-c2b6-4277-e1c1-aa1adb2a8830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 39, 10)            9710      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                12200     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 971)               49521     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71,431\n",
            "Trainable params: 71,431\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=500, verbose=2)"
      ],
      "metadata": {
        "id": "AtidzATd3r5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc21e2c8-580e-4b7b-d482-9e62275866b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "63/63 - 7s - loss: 6.7660 - accuracy: 0.0266 - 7s/epoch - 109ms/step\n",
            "Epoch 2/500\n",
            "63/63 - 2s - loss: 6.3291 - accuracy: 0.0361 - 2s/epoch - 33ms/step\n",
            "Epoch 3/500\n",
            "63/63 - 1s - loss: 6.2499 - accuracy: 0.0411 - 1s/epoch - 22ms/step\n",
            "Epoch 4/500\n",
            "63/63 - 1s - loss: 6.2231 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 5/500\n",
            "63/63 - 2s - loss: 6.1970 - accuracy: 0.0411 - 2s/epoch - 31ms/step\n",
            "Epoch 6/500\n",
            "63/63 - 1s - loss: 6.1638 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 7/500\n",
            "63/63 - 1s - loss: 6.1198 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 8/500\n",
            "63/63 - 1s - loss: 6.0693 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 9/500\n",
            "63/63 - 1s - loss: 6.0193 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 10/500\n",
            "63/63 - 1s - loss: 5.9701 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 11/500\n",
            "63/63 - 1s - loss: 5.9269 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 12/500\n",
            "63/63 - 1s - loss: 5.8827 - accuracy: 0.0411 - 1s/epoch - 21ms/step\n",
            "Epoch 13/500\n",
            "63/63 - 1s - loss: 5.8445 - accuracy: 0.0371 - 1s/epoch - 21ms/step\n",
            "Epoch 14/500\n",
            "63/63 - 1s - loss: 5.8029 - accuracy: 0.0401 - 1s/epoch - 21ms/step\n",
            "Epoch 15/500\n",
            "63/63 - 1s - loss: 5.7610 - accuracy: 0.0426 - 1s/epoch - 22ms/step\n",
            "Epoch 16/500\n",
            "63/63 - 1s - loss: 5.7204 - accuracy: 0.0446 - 1s/epoch - 21ms/step\n",
            "Epoch 17/500\n",
            "63/63 - 1s - loss: 5.6803 - accuracy: 0.0431 - 1s/epoch - 21ms/step\n",
            "Epoch 18/500\n",
            "63/63 - 2s - loss: 5.6366 - accuracy: 0.0431 - 2s/epoch - 26ms/step\n",
            "Epoch 19/500\n",
            "63/63 - 2s - loss: 5.5912 - accuracy: 0.0441 - 2s/epoch - 34ms/step\n",
            "Epoch 20/500\n",
            "63/63 - 3s - loss: 5.5474 - accuracy: 0.0461 - 3s/epoch - 41ms/step\n",
            "Epoch 21/500\n",
            "63/63 - 3s - loss: 5.5010 - accuracy: 0.0491 - 3s/epoch - 40ms/step\n",
            "Epoch 22/500\n",
            "63/63 - 2s - loss: 5.4541 - accuracy: 0.0466 - 2s/epoch - 28ms/step\n",
            "Epoch 23/500\n",
            "63/63 - 1s - loss: 5.4087 - accuracy: 0.0506 - 1s/epoch - 21ms/step\n",
            "Epoch 24/500\n",
            "63/63 - 1s - loss: 5.3644 - accuracy: 0.0531 - 1s/epoch - 21ms/step\n",
            "Epoch 25/500\n",
            "63/63 - 1s - loss: 5.3236 - accuracy: 0.0506 - 1s/epoch - 21ms/step\n",
            "Epoch 26/500\n",
            "63/63 - 1s - loss: 5.2786 - accuracy: 0.0551 - 1s/epoch - 22ms/step\n",
            "Epoch 27/500\n",
            "63/63 - 1s - loss: 5.2369 - accuracy: 0.0551 - 1s/epoch - 21ms/step\n",
            "Epoch 28/500\n",
            "63/63 - 1s - loss: 5.1953 - accuracy: 0.0551 - 1s/epoch - 22ms/step\n",
            "Epoch 29/500\n",
            "63/63 - 1s - loss: 5.1561 - accuracy: 0.0637 - 1s/epoch - 22ms/step\n",
            "Epoch 30/500\n",
            "63/63 - 1s - loss: 5.1163 - accuracy: 0.0657 - 1s/epoch - 22ms/step\n",
            "Epoch 31/500\n",
            "63/63 - 1s - loss: 5.0784 - accuracy: 0.0692 - 1s/epoch - 22ms/step\n",
            "Epoch 32/500\n",
            "63/63 - 1s - loss: 5.0383 - accuracy: 0.0697 - 1s/epoch - 22ms/step\n",
            "Epoch 33/500\n",
            "63/63 - 1s - loss: 5.0026 - accuracy: 0.0672 - 1s/epoch - 22ms/step\n",
            "Epoch 34/500\n",
            "63/63 - 1s - loss: 4.9612 - accuracy: 0.0752 - 1s/epoch - 23ms/step\n",
            "Epoch 35/500\n",
            "63/63 - 1s - loss: 4.9266 - accuracy: 0.0782 - 1s/epoch - 23ms/step\n",
            "Epoch 36/500\n",
            "63/63 - 1s - loss: 4.8846 - accuracy: 0.0842 - 1s/epoch - 22ms/step\n",
            "Epoch 37/500\n",
            "63/63 - 1s - loss: 4.8475 - accuracy: 0.0857 - 1s/epoch - 22ms/step\n",
            "Epoch 38/500\n",
            "63/63 - 1s - loss: 4.8086 - accuracy: 0.0877 - 1s/epoch - 21ms/step\n",
            "Epoch 39/500\n",
            "63/63 - 1s - loss: 4.7738 - accuracy: 0.0877 - 1s/epoch - 22ms/step\n",
            "Epoch 40/500\n",
            "63/63 - 1s - loss: 4.7352 - accuracy: 0.0917 - 1s/epoch - 22ms/step\n",
            "Epoch 41/500\n",
            "63/63 - 2s - loss: 4.6958 - accuracy: 0.0942 - 2s/epoch - 32ms/step\n",
            "Epoch 42/500\n",
            "63/63 - 1s - loss: 4.6579 - accuracy: 0.0987 - 1s/epoch - 21ms/step\n",
            "Epoch 43/500\n",
            "63/63 - 1s - loss: 4.6205 - accuracy: 0.1018 - 1s/epoch - 22ms/step\n",
            "Epoch 44/500\n",
            "63/63 - 1s - loss: 4.5785 - accuracy: 0.1033 - 1s/epoch - 22ms/step\n",
            "Epoch 45/500\n",
            "63/63 - 1s - loss: 4.5454 - accuracy: 0.1038 - 1s/epoch - 21ms/step\n",
            "Epoch 46/500\n",
            "63/63 - 1s - loss: 4.5068 - accuracy: 0.1063 - 1s/epoch - 21ms/step\n",
            "Epoch 47/500\n",
            "63/63 - 1s - loss: 4.4656 - accuracy: 0.1143 - 1s/epoch - 21ms/step\n",
            "Epoch 48/500\n",
            "63/63 - 1s - loss: 4.4279 - accuracy: 0.1258 - 1s/epoch - 21ms/step\n",
            "Epoch 49/500\n",
            "63/63 - 1s - loss: 4.3855 - accuracy: 0.1253 - 1s/epoch - 21ms/step\n",
            "Epoch 50/500\n",
            "63/63 - 1s - loss: 4.3494 - accuracy: 0.1293 - 1s/epoch - 22ms/step\n",
            "Epoch 51/500\n",
            "63/63 - 2s - loss: 4.3119 - accuracy: 0.1368 - 2s/epoch - 34ms/step\n",
            "Epoch 52/500\n",
            "63/63 - 2s - loss: 4.2693 - accuracy: 0.1434 - 2s/epoch - 24ms/step\n",
            "Epoch 53/500\n",
            "63/63 - 3s - loss: 4.2314 - accuracy: 0.1439 - 3s/epoch - 40ms/step\n",
            "Epoch 54/500\n",
            "63/63 - 1s - loss: 4.1904 - accuracy: 0.1534 - 1s/epoch - 22ms/step\n",
            "Epoch 55/500\n",
            "63/63 - 1s - loss: 4.1533 - accuracy: 0.1609 - 1s/epoch - 22ms/step\n",
            "Epoch 56/500\n",
            "63/63 - 1s - loss: 4.1125 - accuracy: 0.1604 - 1s/epoch - 22ms/step\n",
            "Epoch 57/500\n",
            "63/63 - 1s - loss: 4.0743 - accuracy: 0.1694 - 1s/epoch - 22ms/step\n",
            "Epoch 58/500\n",
            "63/63 - 1s - loss: 4.0332 - accuracy: 0.1739 - 1s/epoch - 22ms/step\n",
            "Epoch 59/500\n",
            "63/63 - 1s - loss: 3.9952 - accuracy: 0.1850 - 1s/epoch - 22ms/step\n",
            "Epoch 60/500\n",
            "63/63 - 1s - loss: 3.9577 - accuracy: 0.1980 - 1s/epoch - 22ms/step\n",
            "Epoch 61/500\n",
            "63/63 - 1s - loss: 3.9209 - accuracy: 0.2000 - 1s/epoch - 22ms/step\n",
            "Epoch 62/500\n",
            "63/63 - 1s - loss: 3.8790 - accuracy: 0.2095 - 1s/epoch - 22ms/step\n",
            "Epoch 63/500\n",
            "63/63 - 1s - loss: 3.8444 - accuracy: 0.2231 - 1s/epoch - 22ms/step\n",
            "Epoch 64/500\n",
            "63/63 - 1s - loss: 3.8037 - accuracy: 0.2296 - 1s/epoch - 23ms/step\n",
            "Epoch 65/500\n",
            "63/63 - 1s - loss: 3.7657 - accuracy: 0.2356 - 1s/epoch - 22ms/step\n",
            "Epoch 66/500\n",
            "63/63 - 1s - loss: 3.7275 - accuracy: 0.2471 - 1s/epoch - 22ms/step\n",
            "Epoch 67/500\n",
            "63/63 - 1s - loss: 3.6916 - accuracy: 0.2526 - 1s/epoch - 22ms/step\n",
            "Epoch 68/500\n",
            "63/63 - 1s - loss: 3.6521 - accuracy: 0.2622 - 1s/epoch - 22ms/step\n",
            "Epoch 69/500\n",
            "63/63 - 1s - loss: 3.6170 - accuracy: 0.2742 - 1s/epoch - 22ms/step\n",
            "Epoch 70/500\n",
            "63/63 - 1s - loss: 3.5804 - accuracy: 0.2847 - 1s/epoch - 22ms/step\n",
            "Epoch 71/500\n",
            "63/63 - 1s - loss: 3.5418 - accuracy: 0.2967 - 1s/epoch - 22ms/step\n",
            "Epoch 72/500\n",
            "63/63 - 1s - loss: 3.5068 - accuracy: 0.3083 - 1s/epoch - 21ms/step\n",
            "Epoch 73/500\n",
            "63/63 - 1s - loss: 3.4768 - accuracy: 0.3143 - 1s/epoch - 21ms/step\n",
            "Epoch 74/500\n",
            "63/63 - 1s - loss: 3.4371 - accuracy: 0.3213 - 1s/epoch - 21ms/step\n",
            "Epoch 75/500\n",
            "63/63 - 1s - loss: 3.4039 - accuracy: 0.3268 - 1s/epoch - 21ms/step\n",
            "Epoch 76/500\n",
            "63/63 - 1s - loss: 3.3664 - accuracy: 0.3393 - 1s/epoch - 22ms/step\n",
            "Epoch 77/500\n",
            "63/63 - 1s - loss: 3.3308 - accuracy: 0.3479 - 1s/epoch - 21ms/step\n",
            "Epoch 78/500\n",
            "63/63 - 1s - loss: 3.2957 - accuracy: 0.3554 - 1s/epoch - 21ms/step\n",
            "Epoch 79/500\n",
            "63/63 - 1s - loss: 3.2610 - accuracy: 0.3584 - 1s/epoch - 22ms/step\n",
            "Epoch 80/500\n",
            "63/63 - 1s - loss: 3.2245 - accuracy: 0.3709 - 1s/epoch - 21ms/step\n",
            "Epoch 81/500\n",
            "63/63 - 1s - loss: 3.1887 - accuracy: 0.3880 - 1s/epoch - 21ms/step\n",
            "Epoch 82/500\n",
            "63/63 - 1s - loss: 3.1575 - accuracy: 0.3820 - 1s/epoch - 22ms/step\n",
            "Epoch 83/500\n",
            "63/63 - 1s - loss: 3.1230 - accuracy: 0.3940 - 1s/epoch - 21ms/step\n",
            "Epoch 84/500\n",
            "63/63 - 1s - loss: 3.0879 - accuracy: 0.4050 - 1s/epoch - 21ms/step\n",
            "Epoch 85/500\n",
            "63/63 - 1s - loss: 3.0537 - accuracy: 0.4135 - 1s/epoch - 21ms/step\n",
            "Epoch 86/500\n",
            "63/63 - 1s - loss: 3.0234 - accuracy: 0.4256 - 1s/epoch - 22ms/step\n",
            "Epoch 87/500\n",
            "63/63 - 1s - loss: 2.9879 - accuracy: 0.4286 - 1s/epoch - 21ms/step\n",
            "Epoch 88/500\n",
            "63/63 - 1s - loss: 2.9578 - accuracy: 0.4396 - 1s/epoch - 21ms/step\n",
            "Epoch 89/500\n",
            "63/63 - 1s - loss: 2.9247 - accuracy: 0.4476 - 1s/epoch - 21ms/step\n",
            "Epoch 90/500\n",
            "63/63 - 1s - loss: 2.8922 - accuracy: 0.4581 - 1s/epoch - 22ms/step\n",
            "Epoch 91/500\n",
            "63/63 - 1s - loss: 2.8612 - accuracy: 0.4632 - 1s/epoch - 21ms/step\n",
            "Epoch 92/500\n",
            "63/63 - 1s - loss: 2.8307 - accuracy: 0.4697 - 1s/epoch - 21ms/step\n",
            "Epoch 93/500\n",
            "63/63 - 1s - loss: 2.7957 - accuracy: 0.4797 - 1s/epoch - 22ms/step\n",
            "Epoch 94/500\n",
            "63/63 - 1s - loss: 2.7620 - accuracy: 0.4957 - 1s/epoch - 22ms/step\n",
            "Epoch 95/500\n",
            "63/63 - 1s - loss: 2.7338 - accuracy: 0.4907 - 1s/epoch - 22ms/step\n",
            "Epoch 96/500\n",
            "63/63 - 1s - loss: 2.7024 - accuracy: 0.4992 - 1s/epoch - 22ms/step\n",
            "Epoch 97/500\n",
            "63/63 - 1s - loss: 2.6706 - accuracy: 0.5123 - 1s/epoch - 21ms/step\n",
            "Epoch 98/500\n",
            "63/63 - 1s - loss: 2.6438 - accuracy: 0.5173 - 1s/epoch - 21ms/step\n",
            "Epoch 99/500\n",
            "63/63 - 1s - loss: 2.6137 - accuracy: 0.5183 - 1s/epoch - 21ms/step\n",
            "Epoch 100/500\n",
            "63/63 - 1s - loss: 2.5830 - accuracy: 0.5173 - 1s/epoch - 21ms/step\n",
            "Epoch 101/500\n",
            "63/63 - 1s - loss: 2.5570 - accuracy: 0.5298 - 1s/epoch - 22ms/step\n",
            "Epoch 102/500\n",
            "63/63 - 1s - loss: 2.5216 - accuracy: 0.5343 - 1s/epoch - 22ms/step\n",
            "Epoch 103/500\n",
            "63/63 - 1s - loss: 2.4950 - accuracy: 0.5298 - 1s/epoch - 22ms/step\n",
            "Epoch 104/500\n",
            "63/63 - 1s - loss: 2.4673 - accuracy: 0.5474 - 1s/epoch - 21ms/step\n",
            "Epoch 105/500\n",
            "63/63 - 1s - loss: 2.4371 - accuracy: 0.5524 - 1s/epoch - 21ms/step\n",
            "Epoch 106/500\n",
            "63/63 - 1s - loss: 2.4098 - accuracy: 0.5574 - 1s/epoch - 22ms/step\n",
            "Epoch 107/500\n",
            "63/63 - 1s - loss: 2.3790 - accuracy: 0.5654 - 1s/epoch - 22ms/step\n",
            "Epoch 108/500\n",
            "63/63 - 1s - loss: 2.3538 - accuracy: 0.5704 - 1s/epoch - 23ms/step\n",
            "Epoch 109/500\n",
            "63/63 - 1s - loss: 2.3280 - accuracy: 0.5769 - 1s/epoch - 22ms/step\n",
            "Epoch 110/500\n",
            "63/63 - 1s - loss: 2.2994 - accuracy: 0.5810 - 1s/epoch - 21ms/step\n",
            "Epoch 111/500\n",
            "63/63 - 1s - loss: 2.2744 - accuracy: 0.5850 - 1s/epoch - 22ms/step\n",
            "Epoch 112/500\n",
            "63/63 - 1s - loss: 2.2487 - accuracy: 0.5890 - 1s/epoch - 22ms/step\n",
            "Epoch 113/500\n",
            "63/63 - 1s - loss: 2.2206 - accuracy: 0.5990 - 1s/epoch - 22ms/step\n",
            "Epoch 114/500\n",
            "63/63 - 1s - loss: 2.1980 - accuracy: 0.5995 - 1s/epoch - 22ms/step\n",
            "Epoch 115/500\n",
            "63/63 - 1s - loss: 2.1911 - accuracy: 0.5955 - 1s/epoch - 22ms/step\n",
            "Epoch 116/500\n",
            "63/63 - 1s - loss: 2.1620 - accuracy: 0.6040 - 1s/epoch - 22ms/step\n",
            "Epoch 117/500\n",
            "63/63 - 1s - loss: 2.1221 - accuracy: 0.6145 - 1s/epoch - 23ms/step\n",
            "Epoch 118/500\n",
            "63/63 - 1s - loss: 2.0974 - accuracy: 0.6206 - 1s/epoch - 22ms/step\n",
            "Epoch 119/500\n",
            "63/63 - 1s - loss: 2.0757 - accuracy: 0.6216 - 1s/epoch - 22ms/step\n",
            "Epoch 120/500\n",
            "63/63 - 1s - loss: 2.0521 - accuracy: 0.6206 - 1s/epoch - 22ms/step\n",
            "Epoch 121/500\n",
            "63/63 - 1s - loss: 2.0272 - accuracy: 0.6321 - 1s/epoch - 22ms/step\n",
            "Epoch 122/500\n",
            "63/63 - 1s - loss: 2.0025 - accuracy: 0.6326 - 1s/epoch - 21ms/step\n",
            "Epoch 123/500\n",
            "63/63 - 1s - loss: 1.9777 - accuracy: 0.6396 - 1s/epoch - 21ms/step\n",
            "Epoch 124/500\n",
            "63/63 - 1s - loss: 1.9552 - accuracy: 0.6421 - 1s/epoch - 22ms/step\n",
            "Epoch 125/500\n",
            "63/63 - 1s - loss: 1.9303 - accuracy: 0.6456 - 1s/epoch - 22ms/step\n",
            "Epoch 126/500\n",
            "63/63 - 1s - loss: 1.9111 - accuracy: 0.6506 - 1s/epoch - 22ms/step\n",
            "Epoch 127/500\n",
            "63/63 - 2s - loss: 1.8881 - accuracy: 0.6541 - 2s/epoch - 34ms/step\n",
            "Epoch 128/500\n",
            "63/63 - 1s - loss: 1.8714 - accuracy: 0.6581 - 1s/epoch - 22ms/step\n",
            "Epoch 129/500\n",
            "63/63 - 1s - loss: 1.8463 - accuracy: 0.6602 - 1s/epoch - 22ms/step\n",
            "Epoch 130/500\n",
            "63/63 - 1s - loss: 1.8271 - accuracy: 0.6667 - 1s/epoch - 22ms/step\n",
            "Epoch 131/500\n",
            "63/63 - 1s - loss: 1.8035 - accuracy: 0.6687 - 1s/epoch - 22ms/step\n",
            "Epoch 132/500\n",
            "63/63 - 1s - loss: 1.7864 - accuracy: 0.6722 - 1s/epoch - 22ms/step\n",
            "Epoch 133/500\n",
            "63/63 - 1s - loss: 1.7635 - accuracy: 0.6822 - 1s/epoch - 22ms/step\n",
            "Epoch 134/500\n",
            "63/63 - 1s - loss: 1.7457 - accuracy: 0.6812 - 1s/epoch - 21ms/step\n",
            "Epoch 135/500\n",
            "63/63 - 1s - loss: 1.7266 - accuracy: 0.6912 - 1s/epoch - 22ms/step\n",
            "Epoch 136/500\n",
            "63/63 - 1s - loss: 1.7060 - accuracy: 0.6892 - 1s/epoch - 22ms/step\n",
            "Epoch 137/500\n",
            "63/63 - 1s - loss: 1.6847 - accuracy: 0.6952 - 1s/epoch - 21ms/step\n",
            "Epoch 138/500\n",
            "63/63 - 1s - loss: 1.6693 - accuracy: 0.6947 - 1s/epoch - 21ms/step\n",
            "Epoch 139/500\n",
            "63/63 - 1s - loss: 1.6483 - accuracy: 0.7038 - 1s/epoch - 22ms/step\n",
            "Epoch 140/500\n",
            "63/63 - 1s - loss: 1.6350 - accuracy: 0.7028 - 1s/epoch - 22ms/step\n",
            "Epoch 141/500\n",
            "63/63 - 1s - loss: 1.6093 - accuracy: 0.7113 - 1s/epoch - 21ms/step\n",
            "Epoch 142/500\n",
            "63/63 - 1s - loss: 1.5903 - accuracy: 0.7178 - 1s/epoch - 22ms/step\n",
            "Epoch 143/500\n",
            "63/63 - 1s - loss: 1.5765 - accuracy: 0.7138 - 1s/epoch - 22ms/step\n",
            "Epoch 144/500\n",
            "63/63 - 1s - loss: 1.5551 - accuracy: 0.7203 - 1s/epoch - 22ms/step\n",
            "Epoch 145/500\n",
            "63/63 - 1s - loss: 1.5383 - accuracy: 0.7208 - 1s/epoch - 22ms/step\n",
            "Epoch 146/500\n",
            "63/63 - 1s - loss: 1.5192 - accuracy: 0.7273 - 1s/epoch - 21ms/step\n",
            "Epoch 147/500\n",
            "63/63 - 1s - loss: 1.5056 - accuracy: 0.7323 - 1s/epoch - 22ms/step\n",
            "Epoch 148/500\n",
            "63/63 - 1s - loss: 1.4840 - accuracy: 0.7338 - 1s/epoch - 22ms/step\n",
            "Epoch 149/500\n",
            "63/63 - 1s - loss: 1.4703 - accuracy: 0.7404 - 1s/epoch - 22ms/step\n",
            "Epoch 150/500\n",
            "63/63 - 1s - loss: 1.4512 - accuracy: 0.7409 - 1s/epoch - 21ms/step\n",
            "Epoch 151/500\n",
            "63/63 - 1s - loss: 1.4413 - accuracy: 0.7444 - 1s/epoch - 23ms/step\n",
            "Epoch 152/500\n",
            "63/63 - 1s - loss: 1.4243 - accuracy: 0.7444 - 1s/epoch - 21ms/step\n",
            "Epoch 153/500\n",
            "63/63 - 1s - loss: 1.4027 - accuracy: 0.7444 - 1s/epoch - 21ms/step\n",
            "Epoch 154/500\n",
            "63/63 - 1s - loss: 1.3853 - accuracy: 0.7534 - 1s/epoch - 21ms/step\n",
            "Epoch 155/500\n",
            "63/63 - 1s - loss: 1.3704 - accuracy: 0.7574 - 1s/epoch - 21ms/step\n",
            "Epoch 156/500\n",
            "63/63 - 1s - loss: 1.3551 - accuracy: 0.7654 - 1s/epoch - 22ms/step\n",
            "Epoch 157/500\n",
            "63/63 - 1s - loss: 1.3367 - accuracy: 0.7649 - 1s/epoch - 22ms/step\n",
            "Epoch 158/500\n",
            "63/63 - 1s - loss: 1.3256 - accuracy: 0.7639 - 1s/epoch - 22ms/step\n",
            "Epoch 159/500\n",
            "63/63 - 1s - loss: 1.3061 - accuracy: 0.7699 - 1s/epoch - 21ms/step\n",
            "Epoch 160/500\n",
            "63/63 - 1s - loss: 1.2932 - accuracy: 0.7714 - 1s/epoch - 21ms/step\n",
            "Epoch 161/500\n",
            "63/63 - 1s - loss: 1.2819 - accuracy: 0.7679 - 1s/epoch - 21ms/step\n",
            "Epoch 162/500\n",
            "63/63 - 1s - loss: 1.2647 - accuracy: 0.7820 - 1s/epoch - 22ms/step\n",
            "Epoch 163/500\n",
            "63/63 - 1s - loss: 1.2521 - accuracy: 0.7799 - 1s/epoch - 22ms/step\n",
            "Epoch 164/500\n",
            "63/63 - 1s - loss: 1.2407 - accuracy: 0.7794 - 1s/epoch - 22ms/step\n",
            "Epoch 165/500\n",
            "63/63 - 1s - loss: 1.2255 - accuracy: 0.7885 - 1s/epoch - 22ms/step\n",
            "Epoch 166/500\n",
            "63/63 - 1s - loss: 1.2097 - accuracy: 0.7885 - 1s/epoch - 22ms/step\n",
            "Epoch 167/500\n",
            "63/63 - 1s - loss: 1.1962 - accuracy: 0.7885 - 1s/epoch - 21ms/step\n",
            "Epoch 168/500\n",
            "63/63 - 1s - loss: 1.1838 - accuracy: 0.7915 - 1s/epoch - 21ms/step\n",
            "Epoch 169/500\n",
            "63/63 - 1s - loss: 1.1656 - accuracy: 0.7975 - 1s/epoch - 22ms/step\n",
            "Epoch 170/500\n",
            "63/63 - 1s - loss: 1.1555 - accuracy: 0.7995 - 1s/epoch - 21ms/step\n",
            "Epoch 171/500\n",
            "63/63 - 1s - loss: 1.1443 - accuracy: 0.7975 - 1s/epoch - 22ms/step\n",
            "Epoch 172/500\n",
            "63/63 - 1s - loss: 1.1474 - accuracy: 0.8005 - 1s/epoch - 22ms/step\n",
            "Epoch 173/500\n",
            "63/63 - 1s - loss: 1.1438 - accuracy: 0.8025 - 1s/epoch - 22ms/step\n",
            "Epoch 174/500\n",
            "63/63 - 1s - loss: 1.1212 - accuracy: 0.8090 - 1s/epoch - 21ms/step\n",
            "Epoch 175/500\n",
            "63/63 - 2s - loss: 1.0961 - accuracy: 0.8075 - 2s/epoch - 31ms/step\n",
            "Epoch 176/500\n",
            "63/63 - 1s - loss: 1.0813 - accuracy: 0.8110 - 1s/epoch - 24ms/step\n",
            "Epoch 177/500\n",
            "63/63 - 1s - loss: 1.0685 - accuracy: 0.8165 - 1s/epoch - 22ms/step\n",
            "Epoch 178/500\n",
            "63/63 - 1s - loss: 1.0548 - accuracy: 0.8175 - 1s/epoch - 22ms/step\n",
            "Epoch 179/500\n",
            "63/63 - 1s - loss: 1.0408 - accuracy: 0.8211 - 1s/epoch - 21ms/step\n",
            "Epoch 180/500\n",
            "63/63 - 1s - loss: 1.0298 - accuracy: 0.8241 - 1s/epoch - 22ms/step\n",
            "Epoch 181/500\n",
            "63/63 - 1s - loss: 1.0181 - accuracy: 0.8316 - 1s/epoch - 22ms/step\n",
            "Epoch 182/500\n",
            "63/63 - 1s - loss: 1.0070 - accuracy: 0.8276 - 1s/epoch - 22ms/step\n",
            "Epoch 183/500\n",
            "63/63 - 1s - loss: 0.9944 - accuracy: 0.8316 - 1s/epoch - 21ms/step\n",
            "Epoch 184/500\n",
            "63/63 - 1s - loss: 0.9834 - accuracy: 0.8291 - 1s/epoch - 22ms/step\n",
            "Epoch 185/500\n",
            "63/63 - 1s - loss: 0.9731 - accuracy: 0.8361 - 1s/epoch - 21ms/step\n",
            "Epoch 186/500\n",
            "63/63 - 1s - loss: 0.9575 - accuracy: 0.8401 - 1s/epoch - 22ms/step\n",
            "Epoch 187/500\n",
            "63/63 - 1s - loss: 0.9449 - accuracy: 0.8396 - 1s/epoch - 22ms/step\n",
            "Epoch 188/500\n",
            "63/63 - 1s - loss: 0.9388 - accuracy: 0.8386 - 1s/epoch - 22ms/step\n",
            "Epoch 189/500\n",
            "63/63 - 1s - loss: 0.9332 - accuracy: 0.8431 - 1s/epoch - 21ms/step\n",
            "Epoch 190/500\n",
            "63/63 - 1s - loss: 0.9187 - accuracy: 0.8471 - 1s/epoch - 22ms/step\n",
            "Epoch 191/500\n",
            "63/63 - 1s - loss: 0.9030 - accuracy: 0.8516 - 1s/epoch - 21ms/step\n",
            "Epoch 192/500\n",
            "63/63 - 1s - loss: 0.8924 - accuracy: 0.8481 - 1s/epoch - 21ms/step\n",
            "Epoch 193/500\n",
            "63/63 - 1s - loss: 0.8826 - accuracy: 0.8516 - 1s/epoch - 22ms/step\n",
            "Epoch 194/500\n",
            "63/63 - 1s - loss: 0.8724 - accuracy: 0.8541 - 1s/epoch - 22ms/step\n",
            "Epoch 195/500\n",
            "63/63 - 1s - loss: 0.8617 - accuracy: 0.8627 - 1s/epoch - 22ms/step\n",
            "Epoch 196/500\n",
            "63/63 - 1s - loss: 0.8541 - accuracy: 0.8581 - 1s/epoch - 21ms/step\n",
            "Epoch 197/500\n",
            "63/63 - 1s - loss: 0.8434 - accuracy: 0.8571 - 1s/epoch - 21ms/step\n",
            "Epoch 198/500\n",
            "63/63 - 1s - loss: 0.8362 - accuracy: 0.8632 - 1s/epoch - 22ms/step\n",
            "Epoch 199/500\n",
            "63/63 - 1s - loss: 0.8307 - accuracy: 0.8637 - 1s/epoch - 22ms/step\n",
            "Epoch 200/500\n",
            "63/63 - 1s - loss: 0.8155 - accuracy: 0.8682 - 1s/epoch - 21ms/step\n",
            "Epoch 201/500\n",
            "63/63 - 1s - loss: 0.8057 - accuracy: 0.8722 - 1s/epoch - 22ms/step\n",
            "Epoch 202/500\n",
            "63/63 - 1s - loss: 0.7992 - accuracy: 0.8727 - 1s/epoch - 22ms/step\n",
            "Epoch 203/500\n",
            "63/63 - 1s - loss: 0.7864 - accuracy: 0.8767 - 1s/epoch - 22ms/step\n",
            "Epoch 204/500\n",
            "63/63 - 1s - loss: 0.7783 - accuracy: 0.8782 - 1s/epoch - 21ms/step\n",
            "Epoch 205/500\n",
            "63/63 - 1s - loss: 0.7687 - accuracy: 0.8757 - 1s/epoch - 21ms/step\n",
            "Epoch 206/500\n",
            "63/63 - 1s - loss: 0.7572 - accuracy: 0.8822 - 1s/epoch - 22ms/step\n",
            "Epoch 207/500\n",
            "63/63 - 1s - loss: 0.7500 - accuracy: 0.8832 - 1s/epoch - 22ms/step\n",
            "Epoch 208/500\n",
            "63/63 - 1s - loss: 0.7436 - accuracy: 0.8832 - 1s/epoch - 21ms/step\n",
            "Epoch 209/500\n",
            "63/63 - 1s - loss: 0.7364 - accuracy: 0.8877 - 1s/epoch - 22ms/step\n",
            "Epoch 210/500\n",
            "63/63 - 1s - loss: 0.7237 - accuracy: 0.8832 - 1s/epoch - 21ms/step\n",
            "Epoch 211/500\n",
            "63/63 - 1s - loss: 0.7172 - accuracy: 0.8902 - 1s/epoch - 21ms/step\n",
            "Epoch 212/500\n",
            "63/63 - 1s - loss: 0.7048 - accuracy: 0.8932 - 1s/epoch - 22ms/step\n",
            "Epoch 213/500\n",
            "63/63 - 1s - loss: 0.6966 - accuracy: 0.8952 - 1s/epoch - 22ms/step\n",
            "Epoch 214/500\n",
            "63/63 - 1s - loss: 0.6924 - accuracy: 0.8922 - 1s/epoch - 21ms/step\n",
            "Epoch 215/500\n",
            "63/63 - 1s - loss: 0.6815 - accuracy: 0.8887 - 1s/epoch - 22ms/step\n",
            "Epoch 216/500\n",
            "63/63 - 1s - loss: 0.6763 - accuracy: 0.8977 - 1s/epoch - 22ms/step\n",
            "Epoch 217/500\n",
            "63/63 - 1s - loss: 0.6717 - accuracy: 0.8992 - 1s/epoch - 22ms/step\n",
            "Epoch 218/500\n",
            "63/63 - 1s - loss: 0.6618 - accuracy: 0.8972 - 1s/epoch - 22ms/step\n",
            "Epoch 219/500\n",
            "63/63 - 1s - loss: 0.6544 - accuracy: 0.9003 - 1s/epoch - 22ms/step\n",
            "Epoch 220/500\n",
            "63/63 - 1s - loss: 0.6462 - accuracy: 0.9013 - 1s/epoch - 21ms/step\n",
            "Epoch 221/500\n",
            "63/63 - 1s - loss: 0.6341 - accuracy: 0.9008 - 1s/epoch - 21ms/step\n",
            "Epoch 222/500\n",
            "63/63 - 1s - loss: 0.6285 - accuracy: 0.9058 - 1s/epoch - 21ms/step\n",
            "Epoch 223/500\n",
            "63/63 - 1s - loss: 0.6225 - accuracy: 0.9098 - 1s/epoch - 22ms/step\n",
            "Epoch 224/500\n",
            "63/63 - 1s - loss: 0.6110 - accuracy: 0.9063 - 1s/epoch - 22ms/step\n",
            "Epoch 225/500\n",
            "63/63 - 1s - loss: 0.6016 - accuracy: 0.9128 - 1s/epoch - 21ms/step\n",
            "Epoch 226/500\n",
            "63/63 - 1s - loss: 0.5956 - accuracy: 0.9133 - 1s/epoch - 21ms/step\n",
            "Epoch 227/500\n",
            "63/63 - 1s - loss: 0.5875 - accuracy: 0.9173 - 1s/epoch - 21ms/step\n",
            "Epoch 228/500\n",
            "63/63 - 1s - loss: 0.5842 - accuracy: 0.9118 - 1s/epoch - 21ms/step\n",
            "Epoch 229/500\n",
            "63/63 - 1s - loss: 0.5994 - accuracy: 0.9133 - 1s/epoch - 21ms/step\n",
            "Epoch 230/500\n",
            "63/63 - 1s - loss: 0.5773 - accuracy: 0.9123 - 1s/epoch - 22ms/step\n",
            "Epoch 231/500\n",
            "63/63 - 1s - loss: 0.5624 - accuracy: 0.9213 - 1s/epoch - 21ms/step\n",
            "Epoch 232/500\n",
            "63/63 - 1s - loss: 0.5553 - accuracy: 0.9208 - 1s/epoch - 22ms/step\n",
            "Epoch 233/500\n",
            "63/63 - 1s - loss: 0.5463 - accuracy: 0.9218 - 1s/epoch - 21ms/step\n",
            "Epoch 234/500\n",
            "63/63 - 1s - loss: 0.5409 - accuracy: 0.9223 - 1s/epoch - 21ms/step\n",
            "Epoch 235/500\n",
            "63/63 - 1s - loss: 0.5343 - accuracy: 0.9238 - 1s/epoch - 21ms/step\n",
            "Epoch 236/500\n",
            "63/63 - 1s - loss: 0.5272 - accuracy: 0.9238 - 1s/epoch - 21ms/step\n",
            "Epoch 237/500\n",
            "63/63 - 1s - loss: 0.5220 - accuracy: 0.9268 - 1s/epoch - 22ms/step\n",
            "Epoch 238/500\n",
            "63/63 - 1s - loss: 0.5164 - accuracy: 0.9258 - 1s/epoch - 22ms/step\n",
            "Epoch 239/500\n",
            "63/63 - 1s - loss: 0.5099 - accuracy: 0.9268 - 1s/epoch - 22ms/step\n",
            "Epoch 240/500\n",
            "63/63 - 1s - loss: 0.5065 - accuracy: 0.9273 - 1s/epoch - 21ms/step\n",
            "Epoch 241/500\n",
            "63/63 - 1s - loss: 0.5010 - accuracy: 0.9293 - 1s/epoch - 21ms/step\n",
            "Epoch 242/500\n",
            "63/63 - 1s - loss: 0.4912 - accuracy: 0.9313 - 1s/epoch - 21ms/step\n",
            "Epoch 243/500\n",
            "63/63 - 1s - loss: 0.4905 - accuracy: 0.9313 - 1s/epoch - 22ms/step\n",
            "Epoch 244/500\n",
            "63/63 - 1s - loss: 0.4933 - accuracy: 0.9308 - 1s/epoch - 22ms/step\n",
            "Epoch 245/500\n",
            "63/63 - 1s - loss: 0.4777 - accuracy: 0.9328 - 1s/epoch - 22ms/step\n",
            "Epoch 246/500\n",
            "63/63 - 1s - loss: 0.4668 - accuracy: 0.9368 - 1s/epoch - 21ms/step\n",
            "Epoch 247/500\n",
            "63/63 - 1s - loss: 0.4603 - accuracy: 0.9343 - 1s/epoch - 21ms/step\n",
            "Epoch 248/500\n",
            "63/63 - 1s - loss: 0.4595 - accuracy: 0.9343 - 1s/epoch - 21ms/step\n",
            "Epoch 249/500\n",
            "63/63 - 1s - loss: 0.4608 - accuracy: 0.9363 - 1s/epoch - 21ms/step\n",
            "Epoch 250/500\n",
            "63/63 - 1s - loss: 0.4449 - accuracy: 0.9378 - 1s/epoch - 22ms/step\n",
            "Epoch 251/500\n",
            "63/63 - 1s - loss: 0.4389 - accuracy: 0.9363 - 1s/epoch - 21ms/step\n",
            "Epoch 252/500\n",
            "63/63 - 1s - loss: 0.4337 - accuracy: 0.9419 - 1s/epoch - 21ms/step\n",
            "Epoch 253/500\n",
            "63/63 - 1s - loss: 0.4284 - accuracy: 0.9424 - 1s/epoch - 21ms/step\n",
            "Epoch 254/500\n",
            "63/63 - 1s - loss: 0.4240 - accuracy: 0.9383 - 1s/epoch - 21ms/step\n",
            "Epoch 255/500\n",
            "63/63 - 1s - loss: 0.4235 - accuracy: 0.9398 - 1s/epoch - 21ms/step\n",
            "Epoch 256/500\n",
            "63/63 - 1s - loss: 0.4128 - accuracy: 0.9444 - 1s/epoch - 21ms/step\n",
            "Epoch 257/500\n",
            "63/63 - 1s - loss: 0.4096 - accuracy: 0.9444 - 1s/epoch - 22ms/step\n",
            "Epoch 258/500\n",
            "63/63 - 1s - loss: 0.4120 - accuracy: 0.9424 - 1s/epoch - 21ms/step\n",
            "Epoch 259/500\n",
            "63/63 - 1s - loss: 0.4029 - accuracy: 0.9424 - 1s/epoch - 22ms/step\n",
            "Epoch 260/500\n",
            "63/63 - 1s - loss: 0.3919 - accuracy: 0.9484 - 1s/epoch - 21ms/step\n",
            "Epoch 261/500\n",
            "63/63 - 1s - loss: 0.3880 - accuracy: 0.9474 - 1s/epoch - 22ms/step\n",
            "Epoch 262/500\n",
            "63/63 - 1s - loss: 0.3834 - accuracy: 0.9504 - 1s/epoch - 22ms/step\n",
            "Epoch 263/500\n",
            "63/63 - 1s - loss: 0.3799 - accuracy: 0.9504 - 1s/epoch - 22ms/step\n",
            "Epoch 264/500\n",
            "63/63 - 1s - loss: 0.3722 - accuracy: 0.9519 - 1s/epoch - 22ms/step\n",
            "Epoch 265/500\n",
            "63/63 - 1s - loss: 0.3679 - accuracy: 0.9519 - 1s/epoch - 21ms/step\n",
            "Epoch 266/500\n",
            "63/63 - 1s - loss: 0.3624 - accuracy: 0.9529 - 1s/epoch - 22ms/step\n",
            "Epoch 267/500\n",
            "63/63 - 1s - loss: 0.3586 - accuracy: 0.9544 - 1s/epoch - 22ms/step\n",
            "Epoch 268/500\n",
            "63/63 - 1s - loss: 0.3536 - accuracy: 0.9554 - 1s/epoch - 22ms/step\n",
            "Epoch 269/500\n",
            "63/63 - 1s - loss: 0.3483 - accuracy: 0.9534 - 1s/epoch - 22ms/step\n",
            "Epoch 270/500\n",
            "63/63 - 1s - loss: 0.3628 - accuracy: 0.9524 - 1s/epoch - 22ms/step\n",
            "Epoch 271/500\n",
            "63/63 - 1s - loss: 0.3703 - accuracy: 0.9504 - 1s/epoch - 22ms/step\n",
            "Epoch 272/500\n",
            "63/63 - 1s - loss: 0.3581 - accuracy: 0.9534 - 1s/epoch - 22ms/step\n",
            "Epoch 273/500\n",
            "63/63 - 1s - loss: 0.3389 - accuracy: 0.9579 - 1s/epoch - 22ms/step\n",
            "Epoch 274/500\n",
            "63/63 - 1s - loss: 0.3389 - accuracy: 0.9549 - 1s/epoch - 21ms/step\n",
            "Epoch 275/500\n",
            "63/63 - 1s - loss: 0.3343 - accuracy: 0.9569 - 1s/epoch - 22ms/step\n",
            "Epoch 276/500\n",
            "63/63 - 1s - loss: 0.3332 - accuracy: 0.9564 - 1s/epoch - 22ms/step\n",
            "Epoch 277/500\n",
            "63/63 - 1s - loss: 0.3212 - accuracy: 0.9614 - 1s/epoch - 21ms/step\n",
            "Epoch 278/500\n",
            "63/63 - 1s - loss: 0.3148 - accuracy: 0.9629 - 1s/epoch - 21ms/step\n",
            "Epoch 279/500\n",
            "63/63 - 1s - loss: 0.3091 - accuracy: 0.9604 - 1s/epoch - 22ms/step\n",
            "Epoch 280/500\n",
            "63/63 - 1s - loss: 0.3050 - accuracy: 0.9624 - 1s/epoch - 21ms/step\n",
            "Epoch 281/500\n",
            "63/63 - 1s - loss: 0.3023 - accuracy: 0.9629 - 1s/epoch - 22ms/step\n",
            "Epoch 282/500\n",
            "63/63 - 1s - loss: 0.2976 - accuracy: 0.9639 - 1s/epoch - 22ms/step\n",
            "Epoch 283/500\n",
            "63/63 - 1s - loss: 0.2934 - accuracy: 0.9634 - 1s/epoch - 22ms/step\n",
            "Epoch 284/500\n",
            "63/63 - 1s - loss: 0.2891 - accuracy: 0.9654 - 1s/epoch - 22ms/step\n",
            "Epoch 285/500\n",
            "63/63 - 1s - loss: 0.2849 - accuracy: 0.9659 - 1s/epoch - 21ms/step\n",
            "Epoch 286/500\n",
            "63/63 - 1s - loss: 0.2862 - accuracy: 0.9644 - 1s/epoch - 22ms/step\n",
            "Epoch 287/500\n",
            "63/63 - 1s - loss: 0.2859 - accuracy: 0.9639 - 1s/epoch - 22ms/step\n",
            "Epoch 288/500\n",
            "63/63 - 1s - loss: 0.3276 - accuracy: 0.9554 - 1s/epoch - 21ms/step\n",
            "Epoch 289/500\n",
            "63/63 - 1s - loss: 0.2848 - accuracy: 0.9694 - 1s/epoch - 21ms/step\n",
            "Epoch 290/500\n",
            "63/63 - 1s - loss: 0.2751 - accuracy: 0.9674 - 1s/epoch - 22ms/step\n",
            "Epoch 291/500\n",
            "63/63 - 1s - loss: 0.2696 - accuracy: 0.9679 - 1s/epoch - 21ms/step\n",
            "Epoch 292/500\n",
            "63/63 - 1s - loss: 0.2644 - accuracy: 0.9694 - 1s/epoch - 22ms/step\n",
            "Epoch 293/500\n",
            "63/63 - 1s - loss: 0.2654 - accuracy: 0.9694 - 1s/epoch - 21ms/step\n",
            "Epoch 294/500\n",
            "63/63 - 1s - loss: 0.2590 - accuracy: 0.9714 - 1s/epoch - 22ms/step\n",
            "Epoch 295/500\n",
            "63/63 - 1s - loss: 0.2551 - accuracy: 0.9719 - 1s/epoch - 22ms/step\n",
            "Epoch 296/500\n",
            "63/63 - 1s - loss: 0.2493 - accuracy: 0.9724 - 1s/epoch - 21ms/step\n",
            "Epoch 297/500\n",
            "63/63 - 1s - loss: 0.2469 - accuracy: 0.9709 - 1s/epoch - 22ms/step\n",
            "Epoch 298/500\n",
            "63/63 - 1s - loss: 0.2448 - accuracy: 0.9724 - 1s/epoch - 22ms/step\n",
            "Epoch 299/500\n",
            "63/63 - 1s - loss: 0.2404 - accuracy: 0.9734 - 1s/epoch - 21ms/step\n",
            "Epoch 300/500\n",
            "63/63 - 1s - loss: 0.2376 - accuracy: 0.9734 - 1s/epoch - 22ms/step\n",
            "Epoch 301/500\n",
            "63/63 - 1s - loss: 0.2361 - accuracy: 0.9709 - 1s/epoch - 22ms/step\n",
            "Epoch 302/500\n",
            "63/63 - 1s - loss: 0.2335 - accuracy: 0.9729 - 1s/epoch - 21ms/step\n",
            "Epoch 303/500\n",
            "63/63 - 1s - loss: 0.2310 - accuracy: 0.9734 - 1s/epoch - 22ms/step\n",
            "Epoch 304/500\n",
            "63/63 - 1s - loss: 0.2265 - accuracy: 0.9749 - 1s/epoch - 22ms/step\n",
            "Epoch 305/500\n",
            "63/63 - 1s - loss: 0.2236 - accuracy: 0.9749 - 1s/epoch - 22ms/step\n",
            "Epoch 306/500\n",
            "63/63 - 1s - loss: 0.2204 - accuracy: 0.9754 - 1s/epoch - 22ms/step\n",
            "Epoch 307/500\n",
            "63/63 - 1s - loss: 0.2202 - accuracy: 0.9744 - 1s/epoch - 21ms/step\n",
            "Epoch 308/500\n",
            "63/63 - 1s - loss: 0.2154 - accuracy: 0.9764 - 1s/epoch - 22ms/step\n",
            "Epoch 309/500\n",
            "63/63 - 1s - loss: 0.2150 - accuracy: 0.9744 - 1s/epoch - 22ms/step\n",
            "Epoch 310/500\n",
            "63/63 - 1s - loss: 0.2108 - accuracy: 0.9749 - 1s/epoch - 22ms/step\n",
            "Epoch 311/500\n",
            "63/63 - 1s - loss: 0.2073 - accuracy: 0.9764 - 1s/epoch - 21ms/step\n",
            "Epoch 312/500\n",
            "63/63 - 1s - loss: 0.2056 - accuracy: 0.9779 - 1s/epoch - 23ms/step\n",
            "Epoch 313/500\n",
            "63/63 - 1s - loss: 0.2014 - accuracy: 0.9769 - 1s/epoch - 22ms/step\n",
            "Epoch 314/500\n",
            "63/63 - 1s - loss: 0.1985 - accuracy: 0.9784 - 1s/epoch - 21ms/step\n",
            "Epoch 315/500\n",
            "63/63 - 1s - loss: 0.2341 - accuracy: 0.9694 - 1s/epoch - 21ms/step\n",
            "Epoch 316/500\n",
            "63/63 - 1s - loss: 0.2398 - accuracy: 0.9679 - 1s/epoch - 22ms/step\n",
            "Epoch 317/500\n",
            "63/63 - 1s - loss: 0.2879 - accuracy: 0.9584 - 1s/epoch - 21ms/step\n",
            "Epoch 318/500\n",
            "63/63 - 1s - loss: 0.2232 - accuracy: 0.9734 - 1s/epoch - 21ms/step\n",
            "Epoch 319/500\n",
            "63/63 - 1s - loss: 0.2040 - accuracy: 0.9754 - 1s/epoch - 22ms/step\n",
            "Epoch 320/500\n",
            "63/63 - 1s - loss: 0.1953 - accuracy: 0.9789 - 1s/epoch - 22ms/step\n",
            "Epoch 321/500\n",
            "63/63 - 1s - loss: 0.1897 - accuracy: 0.9754 - 1s/epoch - 22ms/step\n",
            "Epoch 322/500\n",
            "63/63 - 1s - loss: 0.1871 - accuracy: 0.9789 - 1s/epoch - 21ms/step\n",
            "Epoch 323/500\n",
            "63/63 - 1s - loss: 0.1849 - accuracy: 0.9769 - 1s/epoch - 22ms/step\n",
            "Epoch 324/500\n",
            "63/63 - 1s - loss: 0.1859 - accuracy: 0.9805 - 1s/epoch - 22ms/step\n",
            "Epoch 325/500\n",
            "63/63 - 1s - loss: 0.1810 - accuracy: 0.9784 - 1s/epoch - 21ms/step\n",
            "Epoch 326/500\n",
            "63/63 - 1s - loss: 0.1785 - accuracy: 0.9789 - 1s/epoch - 22ms/step\n",
            "Epoch 327/500\n",
            "63/63 - 1s - loss: 0.1752 - accuracy: 0.9784 - 1s/epoch - 23ms/step\n",
            "Epoch 328/500\n",
            "63/63 - 1s - loss: 0.1728 - accuracy: 0.9815 - 1s/epoch - 22ms/step\n",
            "Epoch 329/500\n",
            "63/63 - 1s - loss: 0.1705 - accuracy: 0.9789 - 1s/epoch - 22ms/step\n",
            "Epoch 330/500\n",
            "63/63 - 1s - loss: 0.1676 - accuracy: 0.9820 - 1s/epoch - 22ms/step\n",
            "Epoch 331/500\n",
            "63/63 - 1s - loss: 0.1666 - accuracy: 0.9789 - 1s/epoch - 21ms/step\n",
            "Epoch 332/500\n",
            "63/63 - 1s - loss: 0.1635 - accuracy: 0.9810 - 1s/epoch - 21ms/step\n",
            "Epoch 333/500\n",
            "63/63 - 1s - loss: 0.1602 - accuracy: 0.9835 - 1s/epoch - 23ms/step\n",
            "Epoch 334/500\n",
            "63/63 - 1s - loss: 0.1590 - accuracy: 0.9810 - 1s/epoch - 22ms/step\n",
            "Epoch 335/500\n",
            "63/63 - 1s - loss: 0.1578 - accuracy: 0.9815 - 1s/epoch - 22ms/step\n",
            "Epoch 336/500\n",
            "63/63 - 1s - loss: 0.1547 - accuracy: 0.9815 - 1s/epoch - 22ms/step\n",
            "Epoch 337/500\n",
            "63/63 - 1s - loss: 0.1532 - accuracy: 0.9830 - 1s/epoch - 22ms/step\n",
            "Epoch 338/500\n",
            "63/63 - 1s - loss: 0.1503 - accuracy: 0.9825 - 1s/epoch - 23ms/step\n",
            "Epoch 339/500\n",
            "63/63 - 1s - loss: 0.1490 - accuracy: 0.9825 - 1s/epoch - 21ms/step\n",
            "Epoch 340/500\n",
            "63/63 - 1s - loss: 0.1476 - accuracy: 0.9820 - 1s/epoch - 21ms/step\n",
            "Epoch 341/500\n",
            "63/63 - 1s - loss: 0.1453 - accuracy: 0.9835 - 1s/epoch - 22ms/step\n",
            "Epoch 342/500\n",
            "63/63 - 1s - loss: 0.1433 - accuracy: 0.9845 - 1s/epoch - 21ms/step\n",
            "Epoch 343/500\n",
            "63/63 - 2s - loss: 0.1416 - accuracy: 0.9830 - 2s/epoch - 33ms/step\n",
            "Epoch 344/500\n",
            "63/63 - 2s - loss: 0.1496 - accuracy: 0.9820 - 2s/epoch - 38ms/step\n",
            "Epoch 345/500\n",
            "63/63 - 3s - loss: 0.1455 - accuracy: 0.9815 - 3s/epoch - 42ms/step\n",
            "Epoch 346/500\n",
            "63/63 - 3s - loss: 0.1379 - accuracy: 0.9835 - 3s/epoch - 47ms/step\n",
            "Epoch 347/500\n",
            "63/63 - 1s - loss: 0.1352 - accuracy: 0.9825 - 1s/epoch - 22ms/step\n",
            "Epoch 348/500\n",
            "63/63 - 1s - loss: 0.1352 - accuracy: 0.9815 - 1s/epoch - 22ms/step\n",
            "Epoch 349/500\n",
            "63/63 - 1s - loss: 0.1333 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 350/500\n",
            "63/63 - 1s - loss: 0.1359 - accuracy: 0.9825 - 1s/epoch - 22ms/step\n",
            "Epoch 351/500\n",
            "63/63 - 1s - loss: 0.1381 - accuracy: 0.9810 - 1s/epoch - 22ms/step\n",
            "Epoch 352/500\n",
            "63/63 - 1s - loss: 0.1310 - accuracy: 0.9820 - 1s/epoch - 22ms/step\n",
            "Epoch 353/500\n",
            "63/63 - 1s - loss: 0.1271 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 354/500\n",
            "63/63 - 1s - loss: 0.1233 - accuracy: 0.9835 - 1s/epoch - 22ms/step\n",
            "Epoch 355/500\n",
            "63/63 - 1s - loss: 0.1219 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 356/500\n",
            "63/63 - 1s - loss: 0.1203 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 357/500\n",
            "63/63 - 1s - loss: 0.1189 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 358/500\n",
            "63/63 - 1s - loss: 0.1176 - accuracy: 0.9840 - 1s/epoch - 21ms/step\n",
            "Epoch 359/500\n",
            "63/63 - 1s - loss: 0.1160 - accuracy: 0.9820 - 1s/epoch - 23ms/step\n",
            "Epoch 360/500\n",
            "63/63 - 1s - loss: 0.1140 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 361/500\n",
            "63/63 - 1s - loss: 0.1131 - accuracy: 0.9825 - 1s/epoch - 22ms/step\n",
            "Epoch 362/500\n",
            "63/63 - 1s - loss: 0.1129 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 363/500\n",
            "63/63 - 1s - loss: 0.1121 - accuracy: 0.9845 - 1s/epoch - 22ms/step\n",
            "Epoch 364/500\n",
            "63/63 - 1s - loss: 0.1086 - accuracy: 0.9845 - 1s/epoch - 22ms/step\n",
            "Epoch 365/500\n",
            "63/63 - 1s - loss: 0.1085 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 366/500\n",
            "63/63 - 1s - loss: 0.1060 - accuracy: 0.9845 - 1s/epoch - 22ms/step\n",
            "Epoch 367/500\n",
            "63/63 - 1s - loss: 0.1051 - accuracy: 0.9840 - 1s/epoch - 23ms/step\n",
            "Epoch 368/500\n",
            "63/63 - 1s - loss: 0.1039 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 369/500\n",
            "63/63 - 1s - loss: 0.1031 - accuracy: 0.9845 - 1s/epoch - 22ms/step\n",
            "Epoch 370/500\n",
            "63/63 - 1s - loss: 0.1018 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 371/500\n",
            "63/63 - 1s - loss: 0.0995 - accuracy: 0.9845 - 1s/epoch - 22ms/step\n",
            "Epoch 372/500\n",
            "63/63 - 1s - loss: 0.0986 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 373/500\n",
            "63/63 - 1s - loss: 0.1010 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 374/500\n",
            "63/63 - 1s - loss: 0.1142 - accuracy: 0.9850 - 1s/epoch - 22ms/step\n",
            "Epoch 375/500\n",
            "63/63 - 1s - loss: 0.1309 - accuracy: 0.9810 - 1s/epoch - 22ms/step\n",
            "Epoch 376/500\n",
            "63/63 - 1s - loss: 0.1952 - accuracy: 0.9644 - 1s/epoch - 22ms/step\n",
            "Epoch 377/500\n",
            "63/63 - 1s - loss: 0.1270 - accuracy: 0.9825 - 1s/epoch - 22ms/step\n",
            "Epoch 378/500\n",
            "63/63 - 1s - loss: 0.1095 - accuracy: 0.9825 - 1s/epoch - 23ms/step\n",
            "Epoch 379/500\n",
            "63/63 - 1s - loss: 0.1014 - accuracy: 0.9845 - 1s/epoch - 22ms/step\n",
            "Epoch 380/500\n",
            "63/63 - 1s - loss: 0.0995 - accuracy: 0.9850 - 1s/epoch - 22ms/step\n",
            "Epoch 381/500\n",
            "63/63 - 1s - loss: 0.0963 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 382/500\n",
            "63/63 - 1s - loss: 0.0939 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 383/500\n",
            "63/63 - 1s - loss: 0.0922 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 384/500\n",
            "63/63 - 1s - loss: 0.0901 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 385/500\n",
            "63/63 - 1s - loss: 0.0888 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 386/500\n",
            "63/63 - 1s - loss: 0.0875 - accuracy: 0.9875 - 1s/epoch - 21ms/step\n",
            "Epoch 387/500\n",
            "63/63 - 1s - loss: 0.0868 - accuracy: 0.9860 - 1s/epoch - 23ms/step\n",
            "Epoch 388/500\n",
            "63/63 - 1s - loss: 0.0858 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 389/500\n",
            "63/63 - 1s - loss: 0.0844 - accuracy: 0.9865 - 1s/epoch - 21ms/step\n",
            "Epoch 390/500\n",
            "63/63 - 1s - loss: 0.0852 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 391/500\n",
            "63/63 - 1s - loss: 0.0822 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 392/500\n",
            "63/63 - 1s - loss: 0.0820 - accuracy: 0.9865 - 1s/epoch - 21ms/step\n",
            "Epoch 393/500\n",
            "63/63 - 1s - loss: 0.0813 - accuracy: 0.9890 - 1s/epoch - 22ms/step\n",
            "Epoch 394/500\n",
            "63/63 - 1s - loss: 0.0807 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 395/500\n",
            "63/63 - 1s - loss: 0.0799 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 396/500\n",
            "63/63 - 1s - loss: 0.0780 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 397/500\n",
            "63/63 - 1s - loss: 0.0766 - accuracy: 0.9865 - 1s/epoch - 21ms/step\n",
            "Epoch 398/500\n",
            "63/63 - 1s - loss: 0.0762 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 399/500\n",
            "63/63 - 1s - loss: 0.0751 - accuracy: 0.9880 - 1s/epoch - 22ms/step\n",
            "Epoch 400/500\n",
            "63/63 - 1s - loss: 0.0755 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 401/500\n",
            "63/63 - 1s - loss: 0.0738 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 402/500\n",
            "63/63 - 1s - loss: 0.0736 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 403/500\n",
            "63/63 - 1s - loss: 0.0719 - accuracy: 0.9890 - 1s/epoch - 22ms/step\n",
            "Epoch 404/500\n",
            "63/63 - 1s - loss: 0.0726 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 405/500\n",
            "63/63 - 1s - loss: 0.0733 - accuracy: 0.9880 - 1s/epoch - 22ms/step\n",
            "Epoch 406/500\n",
            "63/63 - 1s - loss: 0.0711 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 407/500\n",
            "63/63 - 1s - loss: 0.0722 - accuracy: 0.9880 - 1s/epoch - 22ms/step\n",
            "Epoch 408/500\n",
            "63/63 - 1s - loss: 0.0701 - accuracy: 0.9855 - 1s/epoch - 21ms/step\n",
            "Epoch 409/500\n",
            "63/63 - 1s - loss: 0.0681 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 410/500\n",
            "63/63 - 1s - loss: 0.0730 - accuracy: 0.9860 - 1s/epoch - 23ms/step\n",
            "Epoch 411/500\n",
            "63/63 - 1s - loss: 0.0777 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 412/500\n",
            "63/63 - 1s - loss: 0.0711 - accuracy: 0.9890 - 1s/epoch - 22ms/step\n",
            "Epoch 413/500\n",
            "63/63 - 1s - loss: 0.0708 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 414/500\n",
            "63/63 - 1s - loss: 0.0655 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 415/500\n",
            "63/63 - 1s - loss: 0.0651 - accuracy: 0.9860 - 1s/epoch - 21ms/step\n",
            "Epoch 416/500\n",
            "63/63 - 1s - loss: 0.0637 - accuracy: 0.9885 - 1s/epoch - 22ms/step\n",
            "Epoch 417/500\n",
            "63/63 - 1s - loss: 0.0637 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 418/500\n",
            "63/63 - 1s - loss: 0.0625 - accuracy: 0.9865 - 1s/epoch - 21ms/step\n",
            "Epoch 419/500\n",
            "63/63 - 1s - loss: 0.0618 - accuracy: 0.9880 - 1s/epoch - 21ms/step\n",
            "Epoch 420/500\n",
            "63/63 - 1s - loss: 0.0612 - accuracy: 0.9875 - 1s/epoch - 21ms/step\n",
            "Epoch 421/500\n",
            "63/63 - 1s - loss: 0.0600 - accuracy: 0.9895 - 1s/epoch - 24ms/step\n",
            "Epoch 422/500\n",
            "63/63 - 2s - loss: 0.0599 - accuracy: 0.9870 - 2s/epoch - 25ms/step\n",
            "Epoch 423/500\n",
            "63/63 - 2s - loss: 0.0594 - accuracy: 0.9880 - 2s/epoch - 25ms/step\n",
            "Epoch 424/500\n",
            "63/63 - 1s - loss: 0.0596 - accuracy: 0.9870 - 1s/epoch - 23ms/step\n",
            "Epoch 425/500\n",
            "63/63 - 1s - loss: 0.0579 - accuracy: 0.9880 - 1s/epoch - 22ms/step\n",
            "Epoch 426/500\n",
            "63/63 - 1s - loss: 0.0579 - accuracy: 0.9880 - 1s/epoch - 23ms/step\n",
            "Epoch 427/500\n",
            "63/63 - 1s - loss: 0.0574 - accuracy: 0.9885 - 1s/epoch - 22ms/step\n",
            "Epoch 428/500\n",
            "63/63 - 1s - loss: 0.0575 - accuracy: 0.9880 - 1s/epoch - 22ms/step\n",
            "Epoch 429/500\n",
            "63/63 - 1s - loss: 0.0817 - accuracy: 0.9835 - 1s/epoch - 22ms/step\n",
            "Epoch 430/500\n",
            "63/63 - 1s - loss: 0.1156 - accuracy: 0.9754 - 1s/epoch - 21ms/step\n",
            "Epoch 431/500\n",
            "63/63 - 1s - loss: 0.1147 - accuracy: 0.9779 - 1s/epoch - 23ms/step\n",
            "Epoch 432/500\n",
            "63/63 - 1s - loss: 0.0743 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 433/500\n",
            "63/63 - 1s - loss: 0.0646 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 434/500\n",
            "63/63 - 1s - loss: 0.0596 - accuracy: 0.9850 - 1s/epoch - 22ms/step\n",
            "Epoch 435/500\n",
            "63/63 - 1s - loss: 0.0604 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 436/500\n",
            "63/63 - 1s - loss: 0.0657 - accuracy: 0.9875 - 1s/epoch - 21ms/step\n",
            "Epoch 437/500\n",
            "63/63 - 1s - loss: 0.0567 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 438/500\n",
            "63/63 - 1s - loss: 0.0552 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 439/500\n",
            "63/63 - 1s - loss: 0.0540 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 440/500\n",
            "63/63 - 1s - loss: 0.0530 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 441/500\n",
            "63/63 - 1s - loss: 0.0525 - accuracy: 0.9860 - 1s/epoch - 21ms/step\n",
            "Epoch 442/500\n",
            "63/63 - 1s - loss: 0.0519 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 443/500\n",
            "63/63 - 1s - loss: 0.0513 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 444/500\n",
            "63/63 - 1s - loss: 0.0512 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 445/500\n",
            "63/63 - 1s - loss: 0.0512 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 446/500\n",
            "63/63 - 1s - loss: 0.0498 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 447/500\n",
            "63/63 - 1s - loss: 0.0496 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 448/500\n",
            "63/63 - 1s - loss: 0.0493 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 449/500\n",
            "63/63 - 1s - loss: 0.0488 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 450/500\n",
            "63/63 - 1s - loss: 0.0483 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 451/500\n",
            "63/63 - 1s - loss: 0.0483 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 452/500\n",
            "63/63 - 1s - loss: 0.0477 - accuracy: 0.9860 - 1s/epoch - 21ms/step\n",
            "Epoch 453/500\n",
            "63/63 - 1s - loss: 0.0474 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 454/500\n",
            "63/63 - 1s - loss: 0.0471 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 455/500\n",
            "63/63 - 1s - loss: 0.0463 - accuracy: 0.9860 - 1s/epoch - 21ms/step\n",
            "Epoch 456/500\n",
            "63/63 - 1s - loss: 0.0463 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 457/500\n",
            "63/63 - 1s - loss: 0.0461 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 458/500\n",
            "63/63 - 1s - loss: 0.0458 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 459/500\n",
            "63/63 - 1s - loss: 0.0451 - accuracy: 0.9885 - 1s/epoch - 22ms/step\n",
            "Epoch 460/500\n",
            "63/63 - 1s - loss: 0.0453 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 461/500\n",
            "63/63 - 1s - loss: 0.0443 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 462/500\n",
            "63/63 - 1s - loss: 0.0443 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 463/500\n",
            "63/63 - 1s - loss: 0.0438 - accuracy: 0.9875 - 1s/epoch - 21ms/step\n",
            "Epoch 464/500\n",
            "63/63 - 1s - loss: 0.0436 - accuracy: 0.9890 - 1s/epoch - 22ms/step\n",
            "Epoch 465/500\n",
            "63/63 - 1s - loss: 0.0434 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 466/500\n",
            "63/63 - 1s - loss: 0.0433 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 467/500\n",
            "63/63 - 1s - loss: 0.0431 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 468/500\n",
            "63/63 - 1s - loss: 0.0423 - accuracy: 0.9890 - 1s/epoch - 21ms/step\n",
            "Epoch 469/500\n",
            "63/63 - 1s - loss: 0.0421 - accuracy: 0.9865 - 1s/epoch - 21ms/step\n",
            "Epoch 470/500\n",
            "63/63 - 1s - loss: 0.0421 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 471/500\n",
            "63/63 - 1s - loss: 0.0417 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 472/500\n",
            "63/63 - 1s - loss: 0.0415 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 473/500\n",
            "63/63 - 1s - loss: 0.0415 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 474/500\n",
            "63/63 - 1s - loss: 0.0417 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 475/500\n",
            "63/63 - 1s - loss: 0.0411 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 476/500\n",
            "63/63 - 1s - loss: 0.0407 - accuracy: 0.9865 - 1s/epoch - 21ms/step\n",
            "Epoch 477/500\n",
            "63/63 - 1s - loss: 0.0396 - accuracy: 0.9885 - 1s/epoch - 22ms/step\n",
            "Epoch 478/500\n",
            "63/63 - 1s - loss: 0.0402 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 479/500\n",
            "63/63 - 1s - loss: 0.0396 - accuracy: 0.9870 - 1s/epoch - 21ms/step\n",
            "Epoch 480/500\n",
            "63/63 - 1s - loss: 0.0399 - accuracy: 0.9880 - 1s/epoch - 21ms/step\n",
            "Epoch 481/500\n",
            "63/63 - 1s - loss: 0.0597 - accuracy: 0.9840 - 1s/epoch - 22ms/step\n",
            "Epoch 482/500\n",
            "63/63 - 1s - loss: 0.0940 - accuracy: 0.9739 - 1s/epoch - 21ms/step\n",
            "Epoch 483/500\n",
            "63/63 - 1s - loss: 0.0835 - accuracy: 0.9825 - 1s/epoch - 21ms/step\n",
            "Epoch 484/500\n",
            "63/63 - 1s - loss: 0.0477 - accuracy: 0.9875 - 1s/epoch - 21ms/step\n",
            "Epoch 485/500\n",
            "63/63 - 1s - loss: 0.0422 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 486/500\n",
            "63/63 - 1s - loss: 0.0406 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 487/500\n",
            "63/63 - 1s - loss: 0.0395 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 488/500\n",
            "63/63 - 1s - loss: 0.0388 - accuracy: 0.9875 - 1s/epoch - 21ms/step\n",
            "Epoch 489/500\n",
            "63/63 - 1s - loss: 0.0381 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 490/500\n",
            "63/63 - 1s - loss: 0.0382 - accuracy: 0.9870 - 1s/epoch - 22ms/step\n",
            "Epoch 491/500\n",
            "63/63 - 1s - loss: 0.0379 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 492/500\n",
            "63/63 - 1s - loss: 0.0378 - accuracy: 0.9860 - 1s/epoch - 22ms/step\n",
            "Epoch 493/500\n",
            "63/63 - 1s - loss: 0.0369 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 494/500\n",
            "63/63 - 1s - loss: 0.0376 - accuracy: 0.9855 - 1s/epoch - 21ms/step\n",
            "Epoch 495/500\n",
            "63/63 - 1s - loss: 0.0368 - accuracy: 0.9865 - 1s/epoch - 22ms/step\n",
            "Epoch 496/500\n",
            "63/63 - 1s - loss: 0.0363 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n",
            "Epoch 497/500\n",
            "63/63 - 1s - loss: 0.0360 - accuracy: 0.9880 - 1s/epoch - 22ms/step\n",
            "Epoch 498/500\n",
            "63/63 - 1s - loss: 0.0357 - accuracy: 0.9855 - 1s/epoch - 22ms/step\n",
            "Epoch 499/500\n",
            "63/63 - 1s - loss: 0.0358 - accuracy: 0.9865 - 1s/epoch - 21ms/step\n",
            "Epoch 500/500\n",
            "63/63 - 1s - loss: 0.0355 - accuracy: 0.9875 - 1s/epoch - 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6769d4ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(model, vocabs, max_length-1, 'narendra modi', 6))"
      ],
      "metadata": {
        "id": "4MLKMS7TSO3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c542192-34ee-4530-ddb2-57c96c5831e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "narendra modi\n",
            "narendra modi the\n",
            "narendra modi the dollar\n",
            "narendra modi the dollar india\n",
            "narendra modi the dollar india handled\n",
            "narendra modi the dollar india handled exceptionally\n",
            "narendra modi the dollar india handled exceptionally well\n"
          ]
        }
      ]
    }
  ]
}